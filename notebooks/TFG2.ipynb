{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJJYieiiwUHB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Desactivar la ejecución ansiosa\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Definir las características\n",
        "batch_size = 128\n",
        "input_channels = 96\n",
        "output_channels = 256\n",
        "kernel_size = (7, 7)\n",
        "input_size = (40, 40)\n",
        "\n",
        "# Crear un placeholder para la entrada (batch_size, height, width, channels)\n",
        "input_placeholder = tf.compat.v1.placeholder(tf.float32, shape=(batch_size, input_size[0], input_size[1], input_channels))\n",
        "\n",
        "# Definir la capa convolucional\n",
        "conv_layer = tf.keras.layers.Conv2D(filters=output_channels, kernel_size=kernel_size, strides=(1, 1), padding='valid', activation=tf.nn.relu)\n",
        "\n",
        "# Pasar la entrada a través de la capa convolucional\n",
        "output = conv_layer(input_placeholder)\n",
        "\n",
        "# Inicializar TensorFlow\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "# Simular datos de entrada\n",
        "import numpy as np\n",
        "input_data = np.random.rand(batch_size, input_size[0], input_size[1], input_channels)\n",
        "\n",
        "# Ejecutar la sesión para obtener la salida\n",
        "output_data = sess.run(output, feed_dict={input_placeholder: input_data})\n",
        "\n",
        "# Imprimir la forma de la salida\n",
        "print(\"Shape of the output:\", output_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPWNijaUwwqa",
        "outputId": "1ecc9d3f-2e2f-4782-9bf8-22f091e9c7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the output: (128, 34, 34, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow.compat.v1 as tf\n",
        "from tensorflow import keras\n",
        "tf.disable_v2_behavior()\n",
        "tf.compat.v1.disable_resource_variables()\n",
        "\n",
        "\n",
        "# Load training and test data (MNIST dataset):\n",
        "dataLoader = keras.datasets.mnist\n",
        "(features, labels), (testFeatures, testLabels) = dataLoader.load_data()\n",
        "onehot_labels = np.zeros((labels.shape[0], 10))\n",
        "onehot_labels[np.arange(labels.shape[0]), labels] = 1\n",
        "labels = onehot_labels\n",
        "features = features\n",
        "testFeatures = testFeatures\n",
        "onehot_testLabels = np.zeros((testLabels.shape[0], 10))\n",
        "onehot_testLabels[np.arange(testLabels.shape[0]), testLabels] = 1\n",
        "testLabels = onehot_testLabels\n",
        "\n",
        "# Set the parameters:\n",
        "NumClasses = 10\n",
        "BatchLength = 16\n",
        "Size = [28, 28, 1]\n",
        "NumIteration = 40001\n",
        "LearningRate = 1e-4\n",
        "EvalFreq = 1000\n",
        "NumKernels = [16, 32, 64]\n",
        "\n",
        "\n",
        "# spectral pooling size:\n",
        "#         1/2  - 0\n",
        "#         6/8 - 1\n",
        "specPoolSize = 0\n",
        "\n",
        "\n",
        "def fourier_complex_relu(x):\n",
        "    real = tf.real(x)\n",
        "    imag = tf.imag(x)\n",
        "    return tf.complex(tf.cast(real*real+imag*imag > 0.1, tf.float32)*real, tf.cast(real*real+imag*imag > 0.1, tf.float32)*imag)\n",
        "\n",
        "\n",
        "def convolution_in_freq_domain_without_ifft(f_input, out_channels):\n",
        "    in_shape = f_input.get_shape()\n",
        "    bias_r = tf.get_variable('BiasReal', [out_channels], dtype=tf.float32)\n",
        "    bias_c = tf.get_variable('BiasComp', [out_channels], dtype=tf.float32)\n",
        "    bias = tf.complex(bias_r, bias_c)\n",
        "    # Spectral pooling:\n",
        "    if specPoolSize == 0:\n",
        "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 4), int(in_shape[2] // 4), 0], [-1, int(in_shape[1] // 2), int(in_shape[2] // 2), in_shape[-1]])\n",
        "    elif specPoolSize == 1:\n",
        "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 8), int(in_shape[2] // 8), 0], [-1, int(in_shape[1]) - int(2 * in_shape[1] // 8), int(in_shape[2]) - int(2 * in_shape[2] // 8), in_shape[-1]])\n",
        "    in_shape = f_input.get_shape()\n",
        "    w_r = tf.get_variable('w_r', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
        "    w_i = tf.get_variable('w_i', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
        "    w = tf.complex(w_r, w_i)\n",
        "    fourier_kernel = w\n",
        "    fourier_kernel = tf.tile(tf.expand_dims(fourier_kernel, 0), [BatchLength, 1, 1, 1, 1])\n",
        "    out = []\n",
        "    for ind in range(out_channels):\n",
        "        res = tf.multiply(f_input[:, :, :, :], fourier_kernel[:, :, :, :, ind])\n",
        "        res = tf.add(res, bias[ind])\n",
        "        res = tf.expand_dims(tf.reduce_sum(res, 3), -1)\n",
        "        out.append(res)\n",
        "    out = tf.concat(out, 3)# Con estas líneas utilizando tf.keras.layers.BatchNormalization\n",
        "    norm_real = tf.keras.layers.BatchNormalization()(tf.real(out), training=True)\n",
        "    norm_comp = tf.keras.layers.BatchNormalization()(tf.imag(out), training=True)\n",
        "\n",
        "    out = tf.complex(norm_real, norm_comp)\n",
        "    out = fourier_complex_relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "InputData = tf.placeholder(tf.float32, [None] + Size)  # input images\n",
        "OneHotLabels = tf.placeholder(tf.int32, [None, NumClasses])  # the expected outputs, labels\n",
        "\n",
        "\n",
        "# Take the input to Fourier domain\n",
        "CurrentInput = tf.cast(InputData, tf.complex64)\n",
        "CurrentInput = tf.transpose(CurrentInput, [3, 0, 1, 2])\n",
        "fourierInput = tf.fft2d(CurrentInput, name=None)\n",
        "fourierInput = tf.transpose(fourierInput, [1, 2, 3, 0])\n",
        "fourierInput = tf.roll(fourierInput, shift=[int(Size[0]//2), int(Size[1]//2)], axis=[1, 2])\n",
        "CurrentFilters = Size[-1]\n",
        "# a loop which creates all layers\n",
        "for N in range(len(NumKernels)):\n",
        "    with tf.variable_scope('conv' + str(N)):\n",
        "        fourierInput = convolution_in_freq_domain_without_ifft(fourierInput, NumKernels[N])\n",
        "with tf.variable_scope('FC'):\n",
        "    fourierInput = tf.square(tf.real(fourierInput)) + tf.square(tf.imag(fourierInput))\n",
        "    CurrentShape = fourierInput.get_shape()\n",
        "    FeatureLength = int(CurrentShape[1]*CurrentShape[2]*CurrentShape[3])\n",
        "    FC = tf.reshape(fourierInput, [-1, FeatureLength])\n",
        "    W = tf.get_variable('W', [FeatureLength, NumClasses])\n",
        "    FC = tf.matmul(FC, W)\n",
        "    Bias = tf.get_variable('Bias', [NumClasses])\n",
        "    FC = tf.add(FC, Bias)\n",
        "\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    Loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=OneHotLabels, logits=FC))\n",
        "\n",
        "\n",
        "with tf.name_scope('optimizer'):\n",
        "    Optimizer = tf.train.AdamOptimizer(LearningRate).minimize(Loss)\n",
        "\n",
        "\n",
        "with tf.name_scope('accuracy'):\n",
        "    CorrectPredictions = tf.equal(tf.argmax(FC, 1), tf.argmax(OneHotLabels, 1))\n",
        "    Accuracy = tf.reduce_mean(tf.cast(CorrectPredictions, tf.float32))\n",
        "\n",
        "\n",
        "Init = tf.global_variables_initializer()\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "with tf.Session(config=config) as Sess:\n",
        "    Sess.run(Init)\n",
        "    Step = 1\n",
        "    while Step < NumIteration:\n",
        "        UsedInBatch = random.sample(range(features.shape[0]), BatchLength)\n",
        "        batch_xs = features[UsedInBatch, :]\n",
        "        batch_ys = labels[UsedInBatch, :]\n",
        "        batch_xs = np.reshape(batch_xs, [BatchLength]+Size)\n",
        "        _, Acc, L = Sess.run([Optimizer, Accuracy, Loss], feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "        if (Step % 100) == 0:\n",
        "            print(\"Iteration: \"+str(Step))\n",
        "            print(\"Accuracy:\" + str(Acc))\n",
        "            print(\"Loss:\" + str(L))\n",
        "        if (Step % EvalFreq) == 0:\n",
        "            SumAcc = 0.0\n",
        "            for i in range(0, testFeatures.shape[0]):\n",
        "                batch_xs = testFeatures[i, :]\n",
        "                batch_ys = testLabels[i, :]\n",
        "                batch_xs = np.reshape(batch_xs, [1]+Size)\n",
        "                batch_ys = np.reshape(batch_ys, [1, NumClasses])\n",
        "                a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "                SumAcc += a\n",
        "            print(\"Independent Test set: \"+str(float(SumAcc)/testFeatures.shape[0]))\n",
        "        Step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPueLGfODz5f",
        "outputId": "0539238c-cfba-4a4a-8fde-883df3554e57"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-11ac3a6c921d>:66: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  norm_real = tf.layers.batch_normalization(tf.real(out), training=True)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "<ipython-input-1-11ac3a6c921d>:67: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  norm_comp = tf.layers.batch_normalization(tf.imag(out), training=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 100\n",
            "Accuracy:0.75\n",
            "Loss:0.9307014\n",
            "Iteration: 200\n",
            "Accuracy:0.8125\n",
            "Loss:0.7756984\n",
            "Iteration: 300\n",
            "Accuracy:0.6875\n",
            "Loss:0.93721366\n",
            "Iteration: 400\n",
            "Accuracy:0.75\n",
            "Loss:0.73414516\n",
            "Iteration: 500\n",
            "Accuracy:0.75\n",
            "Loss:1.0891478\n",
            "Iteration: 600\n",
            "Accuracy:0.9375\n",
            "Loss:0.6183495\n",
            "Iteration: 700\n",
            "Accuracy:0.625\n",
            "Loss:0.7580894\n",
            "Iteration: 800\n",
            "Accuracy:0.75\n",
            "Loss:0.69200206\n",
            "Iteration: 900\n",
            "Accuracy:0.875\n",
            "Loss:0.5683291\n",
            "Iteration: 1000\n",
            "Accuracy:0.9375\n",
            "Loss:0.29714042\n",
            "Independent Test set: 0.7118\n",
            "Iteration: 1100\n",
            "Accuracy:0.8125\n",
            "Loss:0.4009171\n",
            "Iteration: 1200\n",
            "Accuracy:0.9375\n",
            "Loss:0.33134592\n",
            "Iteration: 1300\n",
            "Accuracy:0.9375\n",
            "Loss:0.3102257\n",
            "Iteration: 1400\n",
            "Accuracy:0.75\n",
            "Loss:0.7790923\n",
            "Iteration: 1500\n",
            "Accuracy:0.4375\n",
            "Loss:1.6638623\n",
            "Iteration: 1600\n",
            "Accuracy:0.6875\n",
            "Loss:1.5161495\n",
            "Iteration: 1700\n",
            "Accuracy:0.625\n",
            "Loss:0.862098\n",
            "Iteration: 1800\n",
            "Accuracy:0.75\n",
            "Loss:0.78379583\n",
            "Iteration: 1900\n",
            "Accuracy:0.9375\n",
            "Loss:0.4149748\n",
            "Iteration: 2000\n",
            "Accuracy:0.6875\n",
            "Loss:1.2445016\n",
            "Independent Test set: 0.7855\n",
            "Iteration: 2100\n",
            "Accuracy:0.875\n",
            "Loss:0.9993415\n",
            "Iteration: 2200\n",
            "Accuracy:0.8125\n",
            "Loss:0.39241815\n",
            "Iteration: 2300\n",
            "Accuracy:0.875\n",
            "Loss:0.46633112\n",
            "Iteration: 2400\n",
            "Accuracy:0.875\n",
            "Loss:0.21546698\n",
            "Iteration: 2500\n",
            "Accuracy:0.875\n",
            "Loss:0.44083747\n",
            "Iteration: 2600\n",
            "Accuracy:0.875\n",
            "Loss:0.2598291\n",
            "Iteration: 2700\n",
            "Accuracy:0.8125\n",
            "Loss:0.45153236\n",
            "Iteration: 2800\n",
            "Accuracy:0.875\n",
            "Loss:0.56902486\n",
            "Iteration: 2900\n",
            "Accuracy:0.8125\n",
            "Loss:0.6119295\n",
            "Iteration: 3000\n",
            "Accuracy:0.8125\n",
            "Loss:0.40951794\n",
            "Independent Test set: 0.8222\n",
            "Iteration: 3100\n",
            "Accuracy:0.875\n",
            "Loss:0.2286803\n",
            "Iteration: 3200\n",
            "Accuracy:1.0\n",
            "Loss:0.16276324\n",
            "Iteration: 3300\n",
            "Accuracy:0.625\n",
            "Loss:0.83544385\n",
            "Iteration: 3400\n",
            "Accuracy:1.0\n",
            "Loss:0.18956766\n",
            "Iteration: 3500\n",
            "Accuracy:0.8125\n",
            "Loss:0.8250552\n",
            "Iteration: 3600\n",
            "Accuracy:0.8125\n",
            "Loss:0.5637103\n",
            "Iteration: 3700\n",
            "Accuracy:0.875\n",
            "Loss:0.59425914\n",
            "Iteration: 3800\n",
            "Accuracy:0.8125\n",
            "Loss:0.4596687\n",
            "Iteration: 3900\n",
            "Accuracy:0.75\n",
            "Loss:0.6976689\n",
            "Iteration: 4000\n",
            "Accuracy:1.0\n",
            "Loss:0.17527856\n",
            "Independent Test set: 0.8556\n",
            "Iteration: 4100\n",
            "Accuracy:0.875\n",
            "Loss:0.5115496\n",
            "Iteration: 4200\n",
            "Accuracy:0.9375\n",
            "Loss:0.13198158\n",
            "Iteration: 4300\n",
            "Accuracy:0.8125\n",
            "Loss:0.7704651\n",
            "Iteration: 4400\n",
            "Accuracy:0.9375\n",
            "Loss:0.2442329\n",
            "Iteration: 4500\n",
            "Accuracy:0.8125\n",
            "Loss:0.4324\n",
            "Iteration: 4600\n",
            "Accuracy:0.875\n",
            "Loss:0.42513785\n",
            "Iteration: 4700\n",
            "Accuracy:0.6875\n",
            "Loss:0.59042823\n",
            "Iteration: 4800\n",
            "Accuracy:1.0\n",
            "Loss:0.115189314\n",
            "Iteration: 4900\n",
            "Accuracy:0.875\n",
            "Loss:0.3388601\n",
            "Iteration: 5000\n",
            "Accuracy:0.875\n",
            "Loss:0.6024935\n",
            "Independent Test set: 0.869\n",
            "Iteration: 5100\n",
            "Accuracy:0.75\n",
            "Loss:0.55192834\n",
            "Iteration: 5200\n",
            "Accuracy:0.8125\n",
            "Loss:0.46643937\n",
            "Iteration: 5300\n",
            "Accuracy:0.875\n",
            "Loss:0.4818524\n",
            "Iteration: 5400\n",
            "Accuracy:0.8125\n",
            "Loss:0.2588244\n",
            "Iteration: 5500\n",
            "Accuracy:0.75\n",
            "Loss:0.6819197\n",
            "Iteration: 5600\n",
            "Accuracy:0.9375\n",
            "Loss:0.2627153\n",
            "Iteration: 5700\n",
            "Accuracy:0.8125\n",
            "Loss:0.5091272\n",
            "Iteration: 5800\n",
            "Accuracy:0.9375\n",
            "Loss:0.21088088\n",
            "Iteration: 5900\n",
            "Accuracy:0.875\n",
            "Loss:0.46882892\n",
            "Iteration: 6000\n",
            "Accuracy:0.9375\n",
            "Loss:0.21947983\n",
            "Independent Test set: 0.8687\n",
            "Iteration: 6100\n",
            "Accuracy:0.8125\n",
            "Loss:0.5464214\n",
            "Iteration: 6200\n",
            "Accuracy:0.8125\n",
            "Loss:0.6866292\n",
            "Iteration: 6300\n",
            "Accuracy:0.875\n",
            "Loss:0.49863914\n",
            "Iteration: 6400\n",
            "Accuracy:0.9375\n",
            "Loss:0.5232149\n",
            "Iteration: 6500\n",
            "Accuracy:0.9375\n",
            "Loss:0.2508405\n",
            "Iteration: 6600\n",
            "Accuracy:1.0\n",
            "Loss:0.15712042\n",
            "Iteration: 6700\n",
            "Accuracy:0.875\n",
            "Loss:0.2666861\n",
            "Iteration: 6800\n",
            "Accuracy:0.875\n",
            "Loss:0.3458737\n",
            "Iteration: 6900\n",
            "Accuracy:0.75\n",
            "Loss:0.7074169\n",
            "Iteration: 7000\n",
            "Accuracy:0.875\n",
            "Loss:0.58795124\n",
            "Independent Test set: 0.8793\n",
            "Iteration: 7100\n",
            "Accuracy:0.8125\n",
            "Loss:0.63130593\n",
            "Iteration: 7200\n",
            "Accuracy:0.8125\n",
            "Loss:0.440256\n",
            "Iteration: 7300\n",
            "Accuracy:0.9375\n",
            "Loss:0.2501785\n",
            "Iteration: 7400\n",
            "Accuracy:0.8125\n",
            "Loss:0.91826814\n",
            "Iteration: 7500\n",
            "Accuracy:0.75\n",
            "Loss:0.7347498\n",
            "Iteration: 7600\n",
            "Accuracy:0.75\n",
            "Loss:0.657989\n",
            "Iteration: 7700\n",
            "Accuracy:0.875\n",
            "Loss:0.49207085\n",
            "Iteration: 7800\n",
            "Accuracy:0.6875\n",
            "Loss:0.760699\n",
            "Iteration: 7900\n",
            "Accuracy:0.75\n",
            "Loss:0.92867\n",
            "Iteration: 8000\n",
            "Accuracy:0.9375\n",
            "Loss:0.46518347\n",
            "Independent Test set: 0.8905\n",
            "Iteration: 8100\n",
            "Accuracy:0.875\n",
            "Loss:0.83459556\n",
            "Iteration: 8200\n",
            "Accuracy:0.8125\n",
            "Loss:0.43214417\n",
            "Iteration: 8300\n",
            "Accuracy:0.875\n",
            "Loss:0.28137136\n",
            "Iteration: 8400\n",
            "Accuracy:0.8125\n",
            "Loss:0.6192657\n",
            "Iteration: 8500\n",
            "Accuracy:0.6875\n",
            "Loss:0.9584973\n",
            "Iteration: 8600\n",
            "Accuracy:0.875\n",
            "Loss:0.27939162\n",
            "Iteration: 8700\n",
            "Accuracy:0.875\n",
            "Loss:0.22136249\n",
            "Iteration: 8800\n",
            "Accuracy:0.9375\n",
            "Loss:0.5364988\n",
            "Iteration: 8900\n",
            "Accuracy:0.8125\n",
            "Loss:0.8254678\n",
            "Iteration: 9000\n",
            "Accuracy:0.875\n",
            "Loss:0.3353037\n",
            "Independent Test set: 0.8876\n",
            "Iteration: 9100\n",
            "Accuracy:0.6875\n",
            "Loss:1.1857793\n",
            "Iteration: 9200\n",
            "Accuracy:0.875\n",
            "Loss:0.26768908\n",
            "Iteration: 9300\n",
            "Accuracy:0.9375\n",
            "Loss:0.9439441\n",
            "Iteration: 9400\n",
            "Accuracy:0.875\n",
            "Loss:0.5785418\n",
            "Iteration: 9500\n",
            "Accuracy:0.9375\n",
            "Loss:0.3639171\n",
            "Iteration: 9600\n",
            "Accuracy:0.875\n",
            "Loss:0.42773798\n",
            "Iteration: 9700\n",
            "Accuracy:0.8125\n",
            "Loss:0.7199176\n",
            "Iteration: 9800\n",
            "Accuracy:0.8125\n",
            "Loss:0.7698878\n",
            "Iteration: 9900\n",
            "Accuracy:0.875\n",
            "Loss:0.81938046\n",
            "Iteration: 10000\n",
            "Accuracy:0.8125\n",
            "Loss:0.5174816\n",
            "Independent Test set: 0.8824\n",
            "Iteration: 10100\n",
            "Accuracy:0.875\n",
            "Loss:0.5041253\n",
            "Iteration: 10200\n",
            "Accuracy:0.875\n",
            "Loss:0.90541875\n",
            "Iteration: 10300\n",
            "Accuracy:0.875\n",
            "Loss:0.34174222\n",
            "Iteration: 10400\n",
            "Accuracy:0.9375\n",
            "Loss:0.18544224\n",
            "Iteration: 10500\n",
            "Accuracy:0.8125\n",
            "Loss:1.3818479\n",
            "Iteration: 10600\n",
            "Accuracy:1.0\n",
            "Loss:0.16675012\n",
            "Iteration: 10700\n",
            "Accuracy:0.75\n",
            "Loss:0.71775067\n",
            "Iteration: 10800\n",
            "Accuracy:0.875\n",
            "Loss:0.5740377\n",
            "Iteration: 10900\n",
            "Accuracy:0.6875\n",
            "Loss:0.7567481\n",
            "Iteration: 11000\n",
            "Accuracy:0.75\n",
            "Loss:0.5328944\n",
            "Independent Test set: 0.9071\n",
            "Iteration: 11100\n",
            "Accuracy:0.9375\n",
            "Loss:0.46027556\n",
            "Iteration: 11200\n",
            "Accuracy:0.75\n",
            "Loss:0.9351723\n",
            "Iteration: 11300\n",
            "Accuracy:0.8125\n",
            "Loss:0.36586994\n",
            "Iteration: 11400\n",
            "Accuracy:0.75\n",
            "Loss:0.56861055\n",
            "Iteration: 11500\n",
            "Accuracy:0.875\n",
            "Loss:0.5710362\n",
            "Iteration: 11600\n",
            "Accuracy:0.75\n",
            "Loss:0.43566567\n",
            "Iteration: 11700\n",
            "Accuracy:1.0\n",
            "Loss:0.10035388\n",
            "Iteration: 11800\n",
            "Accuracy:0.75\n",
            "Loss:0.53374577\n",
            "Iteration: 11900\n",
            "Accuracy:0.8125\n",
            "Loss:0.3560487\n",
            "Iteration: 12000\n",
            "Accuracy:0.75\n",
            "Loss:0.86598986\n",
            "Independent Test set: 0.9049\n",
            "Iteration: 12100\n",
            "Accuracy:0.8125\n",
            "Loss:0.49069893\n",
            "Iteration: 12200\n",
            "Accuracy:0.875\n",
            "Loss:0.2886985\n",
            "Iteration: 12300\n",
            "Accuracy:0.8125\n",
            "Loss:0.5019736\n",
            "Iteration: 12400\n",
            "Accuracy:0.875\n",
            "Loss:0.6527224\n",
            "Iteration: 12500\n",
            "Accuracy:0.6875\n",
            "Loss:0.7816127\n",
            "Iteration: 12600\n",
            "Accuracy:0.875\n",
            "Loss:0.45929432\n",
            "Iteration: 12700\n",
            "Accuracy:0.8125\n",
            "Loss:0.7077172\n",
            "Iteration: 12800\n",
            "Accuracy:0.75\n",
            "Loss:0.54762805\n",
            "Iteration: 12900\n",
            "Accuracy:0.8125\n",
            "Loss:0.7769927\n",
            "Iteration: 13000\n",
            "Accuracy:0.75\n",
            "Loss:0.5237092\n",
            "Independent Test set: 0.9002\n",
            "Iteration: 13100\n",
            "Accuracy:0.875\n",
            "Loss:0.31730294\n",
            "Iteration: 13200\n",
            "Accuracy:0.9375\n",
            "Loss:0.28074282\n",
            "Iteration: 13300\n",
            "Accuracy:0.8125\n",
            "Loss:0.34109956\n",
            "Iteration: 13400\n",
            "Accuracy:0.875\n",
            "Loss:0.45452\n",
            "Iteration: 13500\n",
            "Accuracy:0.875\n",
            "Loss:0.37441844\n",
            "Iteration: 13600\n",
            "Accuracy:0.9375\n",
            "Loss:0.41087675\n",
            "Iteration: 13700\n",
            "Accuracy:0.875\n",
            "Loss:0.26107773\n",
            "Iteration: 13800\n",
            "Accuracy:0.8125\n",
            "Loss:0.37925816\n",
            "Iteration: 13900\n",
            "Accuracy:0.875\n",
            "Loss:0.46271655\n",
            "Iteration: 14000\n",
            "Accuracy:1.0\n",
            "Loss:0.17170101\n",
            "Independent Test set: 0.9009\n",
            "Iteration: 14100\n",
            "Accuracy:0.9375\n",
            "Loss:0.20468879\n",
            "Iteration: 14200\n",
            "Accuracy:0.8125\n",
            "Loss:0.9643859\n",
            "Iteration: 14300\n",
            "Accuracy:0.9375\n",
            "Loss:0.17250377\n",
            "Iteration: 14400\n",
            "Accuracy:0.875\n",
            "Loss:0.4396553\n",
            "Iteration: 14500\n",
            "Accuracy:0.6875\n",
            "Loss:0.97029966\n",
            "Iteration: 14600\n",
            "Accuracy:0.9375\n",
            "Loss:0.17587167\n",
            "Iteration: 14700\n",
            "Accuracy:0.875\n",
            "Loss:0.21080717\n",
            "Iteration: 14800\n",
            "Accuracy:0.75\n",
            "Loss:0.6630311\n",
            "Iteration: 14900\n",
            "Accuracy:0.8125\n",
            "Loss:0.4341883\n",
            "Iteration: 15000\n",
            "Accuracy:0.8125\n",
            "Loss:0.644723\n",
            "Independent Test set: 0.9103\n",
            "Iteration: 15100\n",
            "Accuracy:0.8125\n",
            "Loss:0.31450507\n",
            "Iteration: 15200\n",
            "Accuracy:0.6875\n",
            "Loss:0.7442549\n",
            "Iteration: 15300\n",
            "Accuracy:0.75\n",
            "Loss:0.47592616\n",
            "Iteration: 15400\n",
            "Accuracy:1.0\n",
            "Loss:0.13313898\n",
            "Iteration: 15500\n",
            "Accuracy:0.875\n",
            "Loss:0.44289914\n",
            "Iteration: 15600\n",
            "Accuracy:0.75\n",
            "Loss:0.7018418\n",
            "Iteration: 15700\n",
            "Accuracy:1.0\n",
            "Loss:0.12581183\n",
            "Iteration: 15800\n",
            "Accuracy:0.75\n",
            "Loss:0.40244868\n",
            "Iteration: 15900\n",
            "Accuracy:0.75\n",
            "Loss:0.64092517\n",
            "Iteration: 16000\n",
            "Accuracy:1.0\n",
            "Loss:0.19252983\n",
            "Independent Test set: 0.9012\n",
            "Iteration: 16100\n",
            "Accuracy:0.875\n",
            "Loss:0.23160641\n",
            "Iteration: 16200\n",
            "Accuracy:0.875\n",
            "Loss:0.5370434\n",
            "Iteration: 16300\n",
            "Accuracy:0.875\n",
            "Loss:0.54687905\n",
            "Iteration: 16400\n",
            "Accuracy:0.75\n",
            "Loss:0.86570805\n",
            "Iteration: 16500\n",
            "Accuracy:0.875\n",
            "Loss:0.38857085\n",
            "Iteration: 16600\n",
            "Accuracy:0.875\n",
            "Loss:0.6044033\n",
            "Iteration: 16700\n",
            "Accuracy:0.9375\n",
            "Loss:0.22919099\n",
            "Iteration: 16800\n",
            "Accuracy:0.875\n",
            "Loss:0.49903446\n",
            "Iteration: 16900\n",
            "Accuracy:0.75\n",
            "Loss:0.3751765\n",
            "Iteration: 17000\n",
            "Accuracy:0.875\n",
            "Loss:0.31094286\n",
            "Independent Test set: 0.906\n",
            "Iteration: 17100\n",
            "Accuracy:0.875\n",
            "Loss:0.546017\n",
            "Iteration: 17200\n",
            "Accuracy:0.9375\n",
            "Loss:0.2829067\n",
            "Iteration: 17300\n",
            "Accuracy:0.9375\n",
            "Loss:0.18696554\n",
            "Iteration: 17400\n",
            "Accuracy:1.0\n",
            "Loss:0.10772212\n",
            "Iteration: 17500\n",
            "Accuracy:0.875\n",
            "Loss:0.57700866\n",
            "Iteration: 17600\n",
            "Accuracy:0.875\n",
            "Loss:0.43596083\n",
            "Iteration: 17700\n",
            "Accuracy:0.8125\n",
            "Loss:0.6112267\n",
            "Iteration: 17800\n",
            "Accuracy:0.875\n",
            "Loss:0.38642997\n",
            "Iteration: 17900\n",
            "Accuracy:0.8125\n",
            "Loss:0.7626176\n",
            "Iteration: 18000\n",
            "Accuracy:0.875\n",
            "Loss:0.26034784\n",
            "Independent Test set: 0.9207\n",
            "Iteration: 18100\n",
            "Accuracy:0.9375\n",
            "Loss:0.2859212\n",
            "Iteration: 18200\n",
            "Accuracy:0.875\n",
            "Loss:0.5639286\n",
            "Iteration: 18300\n",
            "Accuracy:0.9375\n",
            "Loss:0.21703579\n",
            "Iteration: 18400\n",
            "Accuracy:0.875\n",
            "Loss:0.33361876\n",
            "Iteration: 18500\n",
            "Accuracy:0.9375\n",
            "Loss:0.5216829\n",
            "Iteration: 18600\n",
            "Accuracy:0.6875\n",
            "Loss:0.76991755\n",
            "Iteration: 18700\n",
            "Accuracy:1.0\n",
            "Loss:0.13036206\n",
            "Iteration: 18800\n",
            "Accuracy:0.9375\n",
            "Loss:0.18080792\n",
            "Iteration: 18900\n",
            "Accuracy:0.9375\n",
            "Loss:0.13665906\n",
            "Iteration: 19000\n",
            "Accuracy:0.9375\n",
            "Loss:0.3947503\n",
            "Independent Test set: 0.9147\n",
            "Iteration: 19100\n",
            "Accuracy:1.0\n",
            "Loss:0.077233344\n",
            "Iteration: 19200\n",
            "Accuracy:0.6875\n",
            "Loss:0.71626365\n",
            "Iteration: 19300\n",
            "Accuracy:0.875\n",
            "Loss:0.50494576\n",
            "Iteration: 19400\n",
            "Accuracy:0.9375\n",
            "Loss:0.22134557\n",
            "Iteration: 19500\n",
            "Accuracy:0.9375\n",
            "Loss:0.15057798\n",
            "Iteration: 19600\n",
            "Accuracy:0.9375\n",
            "Loss:0.17709747\n",
            "Iteration: 19700\n",
            "Accuracy:0.875\n",
            "Loss:0.8092432\n",
            "Iteration: 19800\n",
            "Accuracy:0.875\n",
            "Loss:0.25170434\n",
            "Iteration: 19900\n",
            "Accuracy:0.8125\n",
            "Loss:0.53553945\n",
            "Iteration: 20000\n",
            "Accuracy:0.8125\n",
            "Loss:0.75828296\n",
            "Independent Test set: 0.9129\n",
            "Iteration: 20100\n",
            "Accuracy:0.9375\n",
            "Loss:0.23708382\n",
            "Iteration: 20200\n",
            "Accuracy:0.8125\n",
            "Loss:0.4452324\n",
            "Iteration: 20300\n",
            "Accuracy:0.9375\n",
            "Loss:0.44654927\n",
            "Iteration: 20400\n",
            "Accuracy:0.9375\n",
            "Loss:0.47563222\n",
            "Iteration: 20500\n",
            "Accuracy:0.75\n",
            "Loss:0.44010103\n",
            "Iteration: 20600\n",
            "Accuracy:0.875\n",
            "Loss:0.26369065\n",
            "Iteration: 20700\n",
            "Accuracy:0.8125\n",
            "Loss:0.47041503\n",
            "Iteration: 20800\n",
            "Accuracy:0.9375\n",
            "Loss:0.19818124\n",
            "Iteration: 20900\n",
            "Accuracy:0.75\n",
            "Loss:0.63603723\n",
            "Iteration: 21000\n",
            "Accuracy:0.8125\n",
            "Loss:0.849723\n",
            "Independent Test set: 0.9112\n",
            "Iteration: 21100\n",
            "Accuracy:0.9375\n",
            "Loss:0.5111314\n",
            "Iteration: 21200\n",
            "Accuracy:0.875\n",
            "Loss:0.23778844\n",
            "Iteration: 21300\n",
            "Accuracy:0.75\n",
            "Loss:0.5895395\n",
            "Iteration: 21400\n",
            "Accuracy:0.8125\n",
            "Loss:0.53826714\n",
            "Iteration: 21500\n",
            "Accuracy:0.875\n",
            "Loss:0.31330907\n",
            "Iteration: 21600\n",
            "Accuracy:0.875\n",
            "Loss:0.4047502\n",
            "Iteration: 21700\n",
            "Accuracy:0.75\n",
            "Loss:0.4733567\n",
            "Iteration: 21800\n",
            "Accuracy:0.75\n",
            "Loss:0.65391594\n",
            "Iteration: 21900\n",
            "Accuracy:0.9375\n",
            "Loss:0.1654497\n",
            "Iteration: 22000\n",
            "Accuracy:1.0\n",
            "Loss:0.13638173\n",
            "Independent Test set: 0.9073\n",
            "Iteration: 22100\n",
            "Accuracy:0.9375\n",
            "Loss:0.33188006\n",
            "Iteration: 22200\n",
            "Accuracy:0.8125\n",
            "Loss:0.48230854\n",
            "Iteration: 22300\n",
            "Accuracy:0.8125\n",
            "Loss:0.4481337\n",
            "Iteration: 22400\n",
            "Accuracy:0.75\n",
            "Loss:0.8027952\n",
            "Iteration: 22500\n",
            "Accuracy:0.875\n",
            "Loss:0.34460485\n",
            "Iteration: 22600\n",
            "Accuracy:0.8125\n",
            "Loss:0.62606215\n",
            "Iteration: 22700\n",
            "Accuracy:0.8125\n",
            "Loss:0.3625908\n",
            "Iteration: 22800\n",
            "Accuracy:0.8125\n",
            "Loss:0.3878925\n",
            "Iteration: 22900\n",
            "Accuracy:1.0\n",
            "Loss:0.091175094\n",
            "Iteration: 23000\n",
            "Accuracy:0.6875\n",
            "Loss:0.71859324\n",
            "Independent Test set: 0.9129\n",
            "Iteration: 23100\n",
            "Accuracy:1.0\n",
            "Loss:0.09353189\n",
            "Iteration: 23200\n",
            "Accuracy:0.6875\n",
            "Loss:1.010964\n",
            "Iteration: 23300\n",
            "Accuracy:0.75\n",
            "Loss:0.8320366\n",
            "Iteration: 23400\n",
            "Accuracy:0.8125\n",
            "Loss:0.38107097\n",
            "Iteration: 23500\n",
            "Accuracy:0.9375\n",
            "Loss:0.14913869\n",
            "Iteration: 23600\n",
            "Accuracy:0.9375\n",
            "Loss:0.17120115\n",
            "Iteration: 23700\n",
            "Accuracy:0.8125\n",
            "Loss:0.77943313\n",
            "Iteration: 23800\n",
            "Accuracy:0.8125\n",
            "Loss:0.32883084\n",
            "Iteration: 23900\n",
            "Accuracy:0.9375\n",
            "Loss:0.24458764\n",
            "Iteration: 24000\n",
            "Accuracy:1.0\n",
            "Loss:0.11322333\n",
            "Independent Test set: 0.9221\n",
            "Iteration: 24100\n",
            "Accuracy:0.875\n",
            "Loss:0.33001614\n",
            "Iteration: 24200\n",
            "Accuracy:0.875\n",
            "Loss:0.7127036\n",
            "Iteration: 24300\n",
            "Accuracy:1.0\n",
            "Loss:0.14889146\n",
            "Iteration: 24400\n",
            "Accuracy:0.75\n",
            "Loss:0.5573946\n",
            "Iteration: 24500\n",
            "Accuracy:0.8125\n",
            "Loss:0.51859814\n",
            "Iteration: 24600\n",
            "Accuracy:0.875\n",
            "Loss:0.30756205\n",
            "Iteration: 24700\n",
            "Accuracy:0.8125\n",
            "Loss:0.7892289\n",
            "Iteration: 24800\n",
            "Accuracy:0.875\n",
            "Loss:0.71013856\n",
            "Iteration: 24900\n",
            "Accuracy:0.875\n",
            "Loss:0.34880129\n",
            "Iteration: 25000\n",
            "Accuracy:0.75\n",
            "Loss:0.6503598\n",
            "Independent Test set: 0.923\n",
            "Iteration: 25100\n",
            "Accuracy:1.0\n",
            "Loss:0.15233308\n",
            "Iteration: 25200\n",
            "Accuracy:0.875\n",
            "Loss:0.30065638\n",
            "Iteration: 25300\n",
            "Accuracy:0.875\n",
            "Loss:0.46681565\n",
            "Iteration: 25400\n",
            "Accuracy:1.0\n",
            "Loss:0.13303281\n",
            "Iteration: 25500\n",
            "Accuracy:0.8125\n",
            "Loss:0.44170865\n",
            "Iteration: 25600\n",
            "Accuracy:0.9375\n",
            "Loss:0.15863729\n",
            "Iteration: 25700\n",
            "Accuracy:0.8125\n",
            "Loss:1.0295547\n",
            "Iteration: 25800\n",
            "Accuracy:0.875\n",
            "Loss:0.32954592\n",
            "Iteration: 25900\n",
            "Accuracy:0.9375\n",
            "Loss:0.3941864\n",
            "Iteration: 26000\n",
            "Accuracy:0.8125\n",
            "Loss:0.7376751\n",
            "Independent Test set: 0.9222\n",
            "Iteration: 26100\n",
            "Accuracy:1.0\n",
            "Loss:0.124190025\n",
            "Iteration: 26200\n",
            "Accuracy:0.9375\n",
            "Loss:0.29270583\n",
            "Iteration: 26300\n",
            "Accuracy:1.0\n",
            "Loss:0.104603514\n",
            "Iteration: 26400\n",
            "Accuracy:0.9375\n",
            "Loss:0.27471417\n",
            "Iteration: 26500\n",
            "Accuracy:1.0\n",
            "Loss:0.096047774\n",
            "Iteration: 26600\n",
            "Accuracy:1.0\n",
            "Loss:0.13287976\n",
            "Iteration: 26700\n",
            "Accuracy:0.8125\n",
            "Loss:0.44837093\n",
            "Iteration: 26800\n",
            "Accuracy:0.8125\n",
            "Loss:0.51514447\n",
            "Iteration: 26900\n",
            "Accuracy:0.75\n",
            "Loss:0.6351292\n",
            "Iteration: 27000\n",
            "Accuracy:0.8125\n",
            "Loss:0.6338892\n",
            "Independent Test set: 0.9104\n",
            "Iteration: 27100\n",
            "Accuracy:0.9375\n",
            "Loss:0.4267329\n",
            "Iteration: 27200\n",
            "Accuracy:0.875\n",
            "Loss:0.28905436\n",
            "Iteration: 27300\n",
            "Accuracy:0.9375\n",
            "Loss:0.15914024\n",
            "Iteration: 27400\n",
            "Accuracy:0.75\n",
            "Loss:1.0051645\n",
            "Iteration: 27500\n",
            "Accuracy:0.875\n",
            "Loss:0.5436129\n",
            "Iteration: 27600\n",
            "Accuracy:0.875\n",
            "Loss:0.29991326\n",
            "Iteration: 27700\n",
            "Accuracy:1.0\n",
            "Loss:0.15100855\n",
            "Iteration: 27800\n",
            "Accuracy:0.9375\n",
            "Loss:0.5237966\n",
            "Iteration: 27900\n",
            "Accuracy:0.9375\n",
            "Loss:0.17041963\n",
            "Iteration: 28000\n",
            "Accuracy:0.875\n",
            "Loss:0.798827\n",
            "Independent Test set: 0.9222\n",
            "Iteration: 28100\n",
            "Accuracy:0.875\n",
            "Loss:0.26884237\n",
            "Iteration: 28200\n",
            "Accuracy:0.75\n",
            "Loss:0.3627724\n",
            "Iteration: 28300\n",
            "Accuracy:0.875\n",
            "Loss:0.15364027\n",
            "Iteration: 28400\n",
            "Accuracy:0.8125\n",
            "Loss:1.1088029\n",
            "Iteration: 28500\n",
            "Accuracy:0.8125\n",
            "Loss:0.46191648\n",
            "Iteration: 28600\n",
            "Accuracy:0.875\n",
            "Loss:0.644207\n",
            "Iteration: 28700\n",
            "Accuracy:0.9375\n",
            "Loss:0.22395141\n",
            "Iteration: 28800\n",
            "Accuracy:0.9375\n",
            "Loss:0.21396357\n",
            "Iteration: 28900\n",
            "Accuracy:0.8125\n",
            "Loss:0.35333508\n",
            "Iteration: 29000\n",
            "Accuracy:0.875\n",
            "Loss:0.43386716\n",
            "Independent Test set: 0.9235\n",
            "Iteration: 29100\n",
            "Accuracy:0.875\n",
            "Loss:0.3226071\n",
            "Iteration: 29200\n",
            "Accuracy:0.875\n",
            "Loss:0.32814735\n",
            "Iteration: 29300\n",
            "Accuracy:0.875\n",
            "Loss:0.5185905\n",
            "Iteration: 29400\n",
            "Accuracy:0.75\n",
            "Loss:0.558374\n",
            "Iteration: 29500\n",
            "Accuracy:0.9375\n",
            "Loss:0.1744577\n",
            "Iteration: 29600\n",
            "Accuracy:0.8125\n",
            "Loss:0.43593523\n",
            "Iteration: 29700\n",
            "Accuracy:0.875\n",
            "Loss:0.31551555\n",
            "Iteration: 29800\n",
            "Accuracy:0.8125\n",
            "Loss:0.6750631\n",
            "Iteration: 29900\n",
            "Accuracy:0.875\n",
            "Loss:0.57264894\n",
            "Iteration: 30000\n",
            "Accuracy:0.8125\n",
            "Loss:0.33082676\n",
            "Independent Test set: 0.9247\n",
            "Iteration: 30100\n",
            "Accuracy:0.9375\n",
            "Loss:0.30340573\n",
            "Iteration: 30200\n",
            "Accuracy:0.75\n",
            "Loss:0.48625728\n",
            "Iteration: 30300\n",
            "Accuracy:0.875\n",
            "Loss:0.57909083\n",
            "Iteration: 30400\n",
            "Accuracy:0.9375\n",
            "Loss:0.17179891\n",
            "Iteration: 30500\n",
            "Accuracy:0.75\n",
            "Loss:0.4506072\n",
            "Iteration: 30600\n",
            "Accuracy:0.9375\n",
            "Loss:0.3134643\n",
            "Iteration: 30700\n",
            "Accuracy:0.9375\n",
            "Loss:0.1788353\n",
            "Iteration: 30800\n",
            "Accuracy:0.8125\n",
            "Loss:0.78521264\n",
            "Iteration: 30900\n",
            "Accuracy:0.6875\n",
            "Loss:0.6910351\n",
            "Iteration: 31000\n",
            "Accuracy:0.9375\n",
            "Loss:0.15157112\n",
            "Independent Test set: 0.9195\n",
            "Iteration: 31100\n",
            "Accuracy:0.75\n",
            "Loss:0.9736649\n",
            "Iteration: 31200\n",
            "Accuracy:0.875\n",
            "Loss:0.43263528\n",
            "Iteration: 31300\n",
            "Accuracy:0.8125\n",
            "Loss:0.55099994\n",
            "Iteration: 31400\n",
            "Accuracy:0.875\n",
            "Loss:0.44181338\n",
            "Iteration: 31500\n",
            "Accuracy:0.8125\n",
            "Loss:0.49117696\n",
            "Iteration: 31600\n",
            "Accuracy:0.875\n",
            "Loss:0.9940175\n",
            "Iteration: 31700\n",
            "Accuracy:0.875\n",
            "Loss:0.33667195\n",
            "Iteration: 31800\n",
            "Accuracy:0.8125\n",
            "Loss:0.340541\n",
            "Iteration: 31900\n",
            "Accuracy:0.875\n",
            "Loss:0.29834384\n",
            "Iteration: 32000\n",
            "Accuracy:0.6875\n",
            "Loss:0.6620632\n",
            "Independent Test set: 0.9173\n",
            "Iteration: 32100\n",
            "Accuracy:0.9375\n",
            "Loss:0.28966695\n",
            "Iteration: 32200\n",
            "Accuracy:1.0\n",
            "Loss:0.17156842\n",
            "Iteration: 32300\n",
            "Accuracy:0.875\n",
            "Loss:0.31146362\n",
            "Iteration: 32400\n",
            "Accuracy:0.875\n",
            "Loss:0.6655748\n",
            "Iteration: 32500\n",
            "Accuracy:0.8125\n",
            "Loss:0.29665628\n",
            "Iteration: 32600\n",
            "Accuracy:0.875\n",
            "Loss:0.6830547\n",
            "Iteration: 32700\n",
            "Accuracy:0.9375\n",
            "Loss:0.1730046\n",
            "Iteration: 32800\n",
            "Accuracy:0.9375\n",
            "Loss:0.15544215\n",
            "Iteration: 32900\n",
            "Accuracy:0.875\n",
            "Loss:0.36988902\n",
            "Iteration: 33000\n",
            "Accuracy:0.9375\n",
            "Loss:0.13512933\n",
            "Independent Test set: 0.9241\n",
            "Iteration: 33100\n",
            "Accuracy:0.8125\n",
            "Loss:0.80095434\n",
            "Iteration: 33200\n",
            "Accuracy:0.8125\n",
            "Loss:0.61740786\n",
            "Iteration: 33300\n",
            "Accuracy:0.9375\n",
            "Loss:0.22730246\n",
            "Iteration: 33400\n",
            "Accuracy:1.0\n",
            "Loss:0.03852213\n",
            "Iteration: 33500\n",
            "Accuracy:1.0\n",
            "Loss:0.04550581\n",
            "Iteration: 33600\n",
            "Accuracy:0.875\n",
            "Loss:0.2921806\n",
            "Iteration: 33700\n",
            "Accuracy:0.9375\n",
            "Loss:0.33949527\n",
            "Iteration: 33800\n",
            "Accuracy:0.8125\n",
            "Loss:0.52956116\n",
            "Iteration: 33900\n",
            "Accuracy:0.9375\n",
            "Loss:0.12545206\n",
            "Iteration: 34000\n",
            "Accuracy:0.75\n",
            "Loss:0.3667599\n",
            "Independent Test set: 0.9203\n",
            "Iteration: 34100\n",
            "Accuracy:0.875\n",
            "Loss:0.4674449\n",
            "Iteration: 34200\n",
            "Accuracy:0.8125\n",
            "Loss:0.73942363\n",
            "Iteration: 34300\n",
            "Accuracy:0.9375\n",
            "Loss:0.19516125\n",
            "Iteration: 34400\n",
            "Accuracy:0.8125\n",
            "Loss:0.65970886\n",
            "Iteration: 34500\n",
            "Accuracy:0.75\n",
            "Loss:0.6366637\n",
            "Iteration: 34600\n",
            "Accuracy:0.8125\n",
            "Loss:0.7513111\n",
            "Iteration: 34700\n",
            "Accuracy:1.0\n",
            "Loss:0.14562275\n",
            "Iteration: 34800\n",
            "Accuracy:0.8125\n",
            "Loss:0.5384775\n",
            "Iteration: 34900\n",
            "Accuracy:0.8125\n",
            "Loss:0.3714875\n",
            "Iteration: 35000\n",
            "Accuracy:0.875\n",
            "Loss:0.47582448\n",
            "Independent Test set: 0.926\n",
            "Iteration: 35100\n",
            "Accuracy:0.9375\n",
            "Loss:0.20655927\n",
            "Iteration: 35200\n",
            "Accuracy:0.875\n",
            "Loss:0.28719184\n",
            "Iteration: 35300\n",
            "Accuracy:1.0\n",
            "Loss:0.11918911\n",
            "Iteration: 35400\n",
            "Accuracy:0.8125\n",
            "Loss:0.5940701\n",
            "Iteration: 35500\n",
            "Accuracy:1.0\n",
            "Loss:0.17127433\n",
            "Iteration: 35600\n",
            "Accuracy:0.9375\n",
            "Loss:0.41191941\n",
            "Iteration: 35700\n",
            "Accuracy:0.8125\n",
            "Loss:0.42623428\n",
            "Iteration: 35800\n",
            "Accuracy:0.9375\n",
            "Loss:0.1801318\n",
            "Iteration: 35900\n",
            "Accuracy:0.5625\n",
            "Loss:1.7904499\n",
            "Iteration: 36000\n",
            "Accuracy:0.875\n",
            "Loss:0.29232\n",
            "Independent Test set: 0.9215\n",
            "Iteration: 36100\n",
            "Accuracy:0.9375\n",
            "Loss:0.19390541\n",
            "Iteration: 36200\n",
            "Accuracy:0.8125\n",
            "Loss:0.37540704\n",
            "Iteration: 36300\n",
            "Accuracy:0.8125\n",
            "Loss:0.46040165\n",
            "Iteration: 36400\n",
            "Accuracy:0.9375\n",
            "Loss:0.2727425\n",
            "Iteration: 36500\n",
            "Accuracy:0.875\n",
            "Loss:0.54658914\n",
            "Iteration: 36600\n",
            "Accuracy:0.875\n",
            "Loss:0.40965658\n",
            "Iteration: 36700\n",
            "Accuracy:0.8125\n",
            "Loss:0.7339926\n",
            "Iteration: 36800\n",
            "Accuracy:1.0\n",
            "Loss:0.10730545\n",
            "Iteration: 36900\n",
            "Accuracy:0.6875\n",
            "Loss:0.81466305\n",
            "Iteration: 37000\n",
            "Accuracy:0.8125\n",
            "Loss:0.56582904\n",
            "Independent Test set: 0.9256\n",
            "Iteration: 37100\n",
            "Accuracy:0.9375\n",
            "Loss:0.10982196\n",
            "Iteration: 37200\n",
            "Accuracy:0.8125\n",
            "Loss:0.5128564\n",
            "Iteration: 37300\n",
            "Accuracy:0.75\n",
            "Loss:0.9493256\n",
            "Iteration: 37400\n",
            "Accuracy:0.9375\n",
            "Loss:0.33352727\n",
            "Iteration: 37500\n",
            "Accuracy:0.8125\n",
            "Loss:0.4348946\n",
            "Iteration: 37600\n",
            "Accuracy:0.9375\n",
            "Loss:0.111451\n",
            "Iteration: 37700\n",
            "Accuracy:0.9375\n",
            "Loss:0.3534158\n",
            "Iteration: 37800\n",
            "Accuracy:0.6875\n",
            "Loss:1.082013\n",
            "Iteration: 37900\n",
            "Accuracy:0.9375\n",
            "Loss:0.16911566\n",
            "Iteration: 38000\n",
            "Accuracy:1.0\n",
            "Loss:0.1381458\n",
            "Independent Test set: 0.9199\n",
            "Iteration: 38100\n",
            "Accuracy:0.8125\n",
            "Loss:0.47859386\n",
            "Iteration: 38200\n",
            "Accuracy:0.875\n",
            "Loss:0.4334278\n",
            "Iteration: 38300\n",
            "Accuracy:0.9375\n",
            "Loss:0.3024065\n",
            "Iteration: 38400\n",
            "Accuracy:0.875\n",
            "Loss:0.24333976\n",
            "Iteration: 38500\n",
            "Accuracy:0.875\n",
            "Loss:0.4598006\n",
            "Iteration: 38600\n",
            "Accuracy:1.0\n",
            "Loss:0.13813688\n",
            "Iteration: 38700\n",
            "Accuracy:0.8125\n",
            "Loss:1.1565703\n",
            "Iteration: 38800\n",
            "Accuracy:0.875\n",
            "Loss:0.50656736\n",
            "Iteration: 38900\n",
            "Accuracy:0.875\n",
            "Loss:0.48973593\n",
            "Iteration: 39000\n",
            "Accuracy:0.875\n",
            "Loss:0.38805702\n",
            "Independent Test set: 0.9235\n",
            "Iteration: 39100\n",
            "Accuracy:0.9375\n",
            "Loss:0.1274752\n",
            "Iteration: 39200\n",
            "Accuracy:0.8125\n",
            "Loss:0.896329\n",
            "Iteration: 39300\n",
            "Accuracy:0.6875\n",
            "Loss:1.8038307\n",
            "Iteration: 39400\n",
            "Accuracy:0.875\n",
            "Loss:0.40107566\n",
            "Iteration: 39500\n",
            "Accuracy:0.9375\n",
            "Loss:0.43649134\n",
            "Iteration: 39600\n",
            "Accuracy:0.75\n",
            "Loss:0.9685544\n",
            "Iteration: 39700\n",
            "Accuracy:0.9375\n",
            "Loss:0.29559225\n",
            "Iteration: 39800\n",
            "Accuracy:0.9375\n",
            "Loss:0.18449232\n",
            "Iteration: 39900\n",
            "Accuracy:0.9375\n",
            "Loss:0.23211323\n",
            "Iteration: 40000\n",
            "Accuracy:0.875\n",
            "Loss:0.41117507\n",
            "Independent Test set: 0.9135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Bw4qyAEOs2",
        "outputId": "5bd80dc7-0f7c-4637-94fc-67477e272ff3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RECONOCIMIENTO DE DÍGITOS\n"
      ],
      "metadata": {
        "id": "3SJX_S1rYX8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow.compat.v1 as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "tf.compat.v1.disable_resource_variables()\n",
        "\n",
        "# Load training and test data (MNIST dataset):\n",
        "dataLoader = keras.datasets.mnist\n",
        "(features, labels), (testFeatures, testLabels) = dataLoader.load_data()\n",
        "onehot_labels = np.zeros((labels.shape[0], 10))\n",
        "onehot_labels[np.arange(labels.shape[0]), labels] = 1\n",
        "labels = onehot_labels\n",
        "features = features\n",
        "testFeatures = testFeatures\n",
        "onehot_testLabels = np.zeros((testLabels.shape[0], 10))\n",
        "onehot_testLabels[np.arange(testLabels.shape[0]), testLabels] = 1\n",
        "testLabels = onehot_testLabels\n",
        "\n",
        "# Set the parameters:\n",
        "NumClasses = 10\n",
        "BatchLength = 16\n",
        "Size = [28, 28, 1]\n",
        "NumIteration = 40001\n",
        "LearningRate = 1e-4\n",
        "EvalFreq = 1000\n",
        "NumKernels = [16, 32, 64]\n",
        "\n",
        "# Spectral pooling size:\n",
        "#         1/2  - 0\n",
        "#         6/8 - 1\n",
        "specPoolSize = 0\n",
        "\n",
        "\n",
        "def fourier_complex_relu(x):\n",
        "    real = tf.real(x)\n",
        "    imag = tf.imag(x)\n",
        "    return tf.complex(tf.cast(real * real + imag * imag > 0.1, tf.float32) * real,\n",
        "                      tf.cast(real * real + imag * imag > 0.1, tf.float32) * imag)\n",
        "\n",
        "\n",
        "def convolution_in_freq_domain_without_ifft(f_input, out_channels):\n",
        "    in_shape = f_input.get_shape()\n",
        "    bias_r = tf.get_variable('BiasReal', [out_channels], dtype=tf.float32)\n",
        "    bias_c = tf.get_variable('BiasComp', [out_channels], dtype=tf.float32)\n",
        "    bias = tf.complex(bias_r, bias_c)\n",
        "    # Spectral pooling:\n",
        "    if specPoolSize == 0:\n",
        "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 4), int(in_shape[2] // 4), 0],\n",
        "                           [-1, int(in_shape[1] // 2), int(in_shape[2] // 2), in_shape[-1]])\n",
        "    elif specPoolSize == 1:\n",
        "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 8), int(in_shape[2] // 8), 0],\n",
        "                           [-1, int(in_shape[1]) - int(2 * in_shape[1] // 8), int(in_shape[2]) - int(2 * in_shape[2] // 8),\n",
        "                            in_shape[-1]])\n",
        "    in_shape = f_input.get_shape()\n",
        "    w_r = tf.get_variable('w_r', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
        "    w_i = tf.get_variable('w_i', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
        "    w = tf.complex(w_r, w_i)\n",
        "    fourier_kernel = w\n",
        "    fourier_kernel = tf.tile(tf.expand_dims(fourier_kernel, 0), [BatchLength, 1, 1, 1, 1])\n",
        "    out = []\n",
        "    for ind in range(out_channels):\n",
        "        res = tf.multiply(f_input[:, :, :, :], fourier_kernel[:, :, :, :, ind])\n",
        "        res = tf.add(res, bias[ind])\n",
        "        res = tf.expand_dims(tf.reduce_sum(res, 3), -1)\n",
        "        out.append(res)\n",
        "    out = tf.concat(out, 3)# Con estas líneas utilizando tf.keras.layers.BatchNormalization\n",
        "    norm_real = tf.keras.layers.BatchNormalization()(tf.real(out), training=True)\n",
        "    norm_comp = tf.keras.layers.BatchNormalization()(tf.imag(out), training=True)\n",
        "\n",
        "    out = tf.complex(norm_real, norm_comp)\n",
        "    out = fourier_complex_relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "InputData = tf.placeholder(tf.float32, [None] + Size)  # input images\n",
        "OneHotLabels = tf.placeholder(tf.int32, [None, NumClasses])  # the expected outputs, labels\n",
        "\n",
        "# Take the input to Fourier domain\n",
        "CurrentInput = tf.cast(InputData, tf.complex64)\n",
        "CurrentInput = tf.transpose(CurrentInput, [3, 0, 1, 2])\n",
        "fourierInput = tf.fft2d(CurrentInput, name=None)\n",
        "fourierInput = tf.transpose(fourierInput, [1, 2, 3, 0])\n",
        "fourierInput = tf.roll(fourierInput, shift=[int(Size[0] // 2), int(Size[1] // 2)], axis=[1, 2])\n",
        "CurrentFilters = Size[-1]\n",
        "\n",
        "# a loop which creates all layers\n",
        "for N in range(len(NumKernels)):\n",
        "    with tf.variable_scope('conv' + str(N)):\n",
        "        fourierInput = convolution_in_freq_domain_without_ifft(fourierInput, NumKernels[N])\n",
        "\n",
        "with tf.variable_scope('FC'):\n",
        "    fourierInput = tf.square(tf.real(fourierInput)) + tf.square(tf.imag(fourierInput))\n",
        "    CurrentShape = fourierInput.get_shape()\n",
        "    FeatureLength = int(CurrentShape[1] * CurrentShape[2] * CurrentShape[3])\n",
        "    FC = tf.reshape(fourierInput, [-1, FeatureLength])\n",
        "    W = tf.get_variable('W', [FeatureLength, NumClasses])\n",
        "    FC = tf.matmul(FC, W)\n",
        "    Bias = tf.get_variable('Bias', [NumClasses])\n",
        "    FC = tf.add(FC, Bias)\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    Loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=OneHotLabels, logits=FC))\n",
        "\n",
        "with tf.name_scope('optimizer'):\n",
        "    Optimizer = tf.train.AdamOptimizer(LearningRate).minimize(Loss)\n",
        "\n",
        "with tf.name_scope('accuracy'):\n",
        "    CorrectPredictions = tf.equal(tf.argmax(FC, 1), tf.argmax(OneHotLabels, 1))\n",
        "    Accuracy = tf.reduce_mean(tf.cast(CorrectPredictions, tf.float32))\n",
        "\n",
        "Init = tf.global_variables_initializer()\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.compat.v1.Session(config=config) as Sess:\n",
        "    Sess.run(Init)\n",
        "    Step = 1\n",
        "    while Step < NumIteration:\n",
        "        UsedInBatch = random.sample(range(features.shape[0]), BatchLength)\n",
        "        batch_xs = features[UsedInBatch, :]\n",
        "        batch_ys = labels[UsedInBatch, :]\n",
        "        batch_xs = np.reshape(batch_xs, [BatchLength] + Size)\n",
        "        _, Acc, L = Sess.run([Optimizer, Accuracy, Loss], feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "        if (Step % 100) == 0:\n",
        "            print(\"Iteration: \" + str(Step))\n",
        "            print(\"Accuracy:\" + str(Acc))\n",
        "            print(\"Loss:\" + str(L))\n",
        "        if (Step % EvalFreq) == 0:\n",
        "            SumAcc = 0.0\n",
        "            for i in range(0, testFeatures.shape[0]):\n",
        "                batch_xs = testFeatures[i, :]\n",
        "                batch_ys = testLabels[i, :]\n",
        "                batch_xs = np.reshape(batch_xs, [1] + Size)\n",
        "                batch_ys = np.reshape(batch_ys, [1, NumClasses])\n",
        "                a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "                SumAcc += a\n",
        "            print(\"Independent Test set: \" + str(float(SumAcc) / testFeatures.shape[0]))\n",
        "        Step += 1\n",
        "\n",
        "    # Después de imprimir la forma de la salida\n",
        "    print(\"Forma de la salida:\", FC.shape)\n",
        "\n",
        "    # Visualizar algunas imágenes y sus predicciones\n",
        "    num_visualize = 5  # Puedes ajustar el número de imágenes a visualizar\n",
        "\n",
        "    # Seleccionar aleatoriamente algunas muestras del conjunto de prueba\n",
        "    visualize_indices = np.random.choice(testFeatures.shape[0], num_visualize, replace=False)\n",
        "\n",
        "    # Crear una sesión sin inicializar explícitamente las variables\n",
        "    for i in visualize_indices:\n",
        "        # Obtener la imagen y la etiqueta verdadera\n",
        "        input_image = testFeatures[i, :]\n",
        "        true_label = testLabels[i, :]\n",
        "\n",
        "        # Preprocesar la entrada para que sea compatible con la red neuronal\n",
        "        input_image = np.reshape(input_image, [1] + Size)\n",
        "\n",
        "        # Obtener la predicción del modelo\n",
        "        prediction = np.argmax(Sess.run(FC, feed_dict={InputData: input_image}), axis=1)\n",
        "\n",
        "        # Visualizar la imagen, la etiqueta verdadera y la predicción\n",
        "        plt.imshow(np.squeeze(input_image), cmap='gray')\n",
        "        plt.title(f'Etiqueta real: {np.argmax(true_label)}, Etiqueta predicha: {prediction[0]}')\n",
        "        plt.show()\n",
        "        plt.pause(2)  # Pausa de 2 segundos entre imágenes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPPUtn3VEkuD",
        "outputId": "19dbd14d-5113-42d0-f992-07e591857900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 100\n",
            "Accuracy:0.8125\n",
            "Loss:1.7138262\n",
            "Iteration: 200\n",
            "Accuracy:0.625\n",
            "Loss:0.7691761\n",
            "Iteration: 300\n",
            "Accuracy:0.6875\n",
            "Loss:0.89332676\n",
            "Iteration: 400\n",
            "Accuracy:0.625\n",
            "Loss:1.023562\n",
            "Iteration: 500\n",
            "Accuracy:0.8125\n",
            "Loss:0.43535298\n",
            "Iteration: 600\n",
            "Accuracy:0.75\n",
            "Loss:0.65603673\n",
            "Iteration: 700\n",
            "Accuracy:0.75\n",
            "Loss:0.87891245\n",
            "Iteration: 800\n",
            "Accuracy:0.5625\n",
            "Loss:0.672582\n",
            "Iteration: 900\n",
            "Accuracy:0.75\n",
            "Loss:1.0081573\n",
            "Iteration: 1000\n",
            "Accuracy:0.5625\n",
            "Loss:1.0080729\n",
            "Independent Test set: 0.7258\n",
            "Iteration: 1100\n",
            "Accuracy:0.8125\n",
            "Loss:0.5857743\n",
            "Iteration: 1200\n",
            "Accuracy:0.8125\n",
            "Loss:0.85653293\n",
            "Iteration: 1300\n",
            "Accuracy:0.9375\n",
            "Loss:0.2487207\n",
            "Iteration: 1400\n",
            "Accuracy:0.875\n",
            "Loss:0.9716654\n",
            "Iteration: 1500\n",
            "Accuracy:0.625\n",
            "Loss:0.7343407\n",
            "Iteration: 1600\n",
            "Accuracy:0.75\n",
            "Loss:0.95528203\n",
            "Iteration: 1700\n",
            "Accuracy:0.6875\n",
            "Loss:0.9565917\n",
            "Iteration: 1800\n",
            "Accuracy:1.0\n",
            "Loss:0.23287597\n",
            "Iteration: 1900\n",
            "Accuracy:0.6875\n",
            "Loss:0.80322546\n",
            "Iteration: 2000\n",
            "Accuracy:1.0\n",
            "Loss:0.15903825\n",
            "Independent Test set: 0.805\n",
            "Iteration: 2100\n",
            "Accuracy:0.9375\n",
            "Loss:0.29603064\n",
            "Iteration: 2200\n",
            "Accuracy:0.8125\n",
            "Loss:0.71173495\n",
            "Iteration: 2300\n",
            "Accuracy:0.75\n",
            "Loss:0.7600834\n",
            "Iteration: 2400\n",
            "Accuracy:0.9375\n",
            "Loss:0.4301256\n",
            "Iteration: 2500\n",
            "Accuracy:0.75\n",
            "Loss:0.45696944\n",
            "Iteration: 2600\n",
            "Accuracy:0.75\n",
            "Loss:0.6687179\n",
            "Iteration: 2700\n",
            "Accuracy:0.9375\n",
            "Loss:0.37846583\n",
            "Iteration: 2800\n",
            "Accuracy:0.8125\n",
            "Loss:1.0242704\n",
            "Iteration: 2900\n",
            "Accuracy:0.875\n",
            "Loss:0.45308608\n",
            "Iteration: 3000\n",
            "Accuracy:0.875\n",
            "Loss:0.42731178\n",
            "Independent Test set: 0.8425\n",
            "Iteration: 3100\n",
            "Accuracy:0.9375\n",
            "Loss:0.46762276\n",
            "Iteration: 3200\n",
            "Accuracy:0.9375\n",
            "Loss:0.5231757\n",
            "Iteration: 3300\n",
            "Accuracy:0.9375\n",
            "Loss:0.46304578\n",
            "Iteration: 3400\n",
            "Accuracy:0.8125\n",
            "Loss:0.41702402\n",
            "Iteration: 3500\n",
            "Accuracy:0.875\n",
            "Loss:0.4502371\n",
            "Iteration: 3600\n",
            "Accuracy:0.9375\n",
            "Loss:0.177621\n",
            "Iteration: 3700\n",
            "Accuracy:0.875\n",
            "Loss:0.2697882\n",
            "Iteration: 3800\n",
            "Accuracy:0.6875\n",
            "Loss:1.4476893\n",
            "Iteration: 3900\n",
            "Accuracy:0.6875\n",
            "Loss:1.1815883\n",
            "Iteration: 4000\n",
            "Accuracy:0.875\n",
            "Loss:0.28095537\n",
            "Independent Test set: 0.8343\n",
            "Iteration: 4100\n",
            "Accuracy:0.6875\n",
            "Loss:1.2233102\n",
            "Iteration: 4200\n",
            "Accuracy:0.875\n",
            "Loss:0.425459\n",
            "Iteration: 4300\n",
            "Accuracy:0.75\n",
            "Loss:0.7576281\n",
            "Iteration: 4400\n",
            "Accuracy:0.875\n",
            "Loss:0.39855808\n",
            "Iteration: 4500\n",
            "Accuracy:0.875\n",
            "Loss:0.364042\n",
            "Iteration: 4600\n",
            "Accuracy:0.875\n",
            "Loss:0.52705956\n",
            "Iteration: 4700\n",
            "Accuracy:0.8125\n",
            "Loss:1.4211994\n",
            "Iteration: 4800\n",
            "Accuracy:0.875\n",
            "Loss:0.7888403\n",
            "Iteration: 4900\n",
            "Accuracy:0.8125\n",
            "Loss:0.70567423\n",
            "Iteration: 5000\n",
            "Accuracy:0.875\n",
            "Loss:0.34188685\n",
            "Independent Test set: 0.8494\n",
            "Iteration: 5100\n",
            "Accuracy:0.875\n",
            "Loss:0.33967328\n",
            "Iteration: 5200\n",
            "Accuracy:0.9375\n",
            "Loss:0.25437135\n",
            "Iteration: 5300\n",
            "Accuracy:0.875\n",
            "Loss:0.2808829\n",
            "Iteration: 5400\n",
            "Accuracy:0.75\n",
            "Loss:0.97257584\n",
            "Iteration: 5500\n",
            "Accuracy:1.0\n",
            "Loss:0.13711028\n",
            "Iteration: 5600\n",
            "Accuracy:0.75\n",
            "Loss:0.66554356\n",
            "Iteration: 5700\n",
            "Accuracy:0.9375\n",
            "Loss:0.28716862\n",
            "Iteration: 5800\n",
            "Accuracy:0.875\n",
            "Loss:0.45871732\n",
            "Iteration: 5900\n",
            "Accuracy:0.75\n",
            "Loss:0.6850312\n",
            "Iteration: 6000\n",
            "Accuracy:0.8125\n",
            "Loss:0.65431666\n",
            "Independent Test set: 0.8697\n",
            "Iteration: 6100\n",
            "Accuracy:0.875\n",
            "Loss:0.5144809\n",
            "Iteration: 6200\n",
            "Accuracy:0.75\n",
            "Loss:0.68312204\n",
            "Iteration: 6300\n",
            "Accuracy:0.9375\n",
            "Loss:0.32442892\n",
            "Iteration: 6400\n",
            "Accuracy:0.875\n",
            "Loss:0.37593684\n",
            "Iteration: 6500\n",
            "Accuracy:0.75\n",
            "Loss:0.63752705\n",
            "Iteration: 6600\n",
            "Accuracy:0.875\n",
            "Loss:0.35536218\n",
            "Iteration: 6700\n",
            "Accuracy:0.625\n",
            "Loss:1.2936158\n",
            "Iteration: 6800\n",
            "Accuracy:0.75\n",
            "Loss:1.0382963\n",
            "Iteration: 6900\n",
            "Accuracy:0.75\n",
            "Loss:0.9604113\n",
            "Iteration: 7000\n",
            "Accuracy:0.75\n",
            "Loss:0.6149775\n",
            "Independent Test set: 0.8869\n",
            "Iteration: 7100\n",
            "Accuracy:0.9375\n",
            "Loss:0.2140907\n",
            "Iteration: 7200\n",
            "Accuracy:0.875\n",
            "Loss:0.55117947\n",
            "Iteration: 7300\n",
            "Accuracy:0.875\n",
            "Loss:0.40305397\n",
            "Iteration: 7400\n",
            "Accuracy:0.5625\n",
            "Loss:0.90132326\n",
            "Iteration: 7500\n",
            "Accuracy:0.8125\n",
            "Loss:0.37663797\n",
            "Iteration: 7600\n",
            "Accuracy:0.875\n",
            "Loss:0.5913435\n",
            "Iteration: 7700\n",
            "Accuracy:0.8125\n",
            "Loss:0.3431949\n",
            "Iteration: 7800\n",
            "Accuracy:0.8125\n",
            "Loss:0.38102436\n",
            "Iteration: 7900\n",
            "Accuracy:1.0\n",
            "Loss:0.1808585\n",
            "Iteration: 8000\n",
            "Accuracy:0.9375\n",
            "Loss:0.15621518\n",
            "Independent Test set: 0.886\n",
            "Iteration: 8100\n",
            "Accuracy:1.0\n",
            "Loss:0.105566986\n",
            "Iteration: 8200\n",
            "Accuracy:0.9375\n",
            "Loss:0.19436055\n",
            "Iteration: 8300\n",
            "Accuracy:0.9375\n",
            "Loss:0.34195706\n",
            "Iteration: 8400\n",
            "Accuracy:0.9375\n",
            "Loss:0.24579054\n",
            "Iteration: 8500\n",
            "Accuracy:0.875\n",
            "Loss:0.48614419\n",
            "Iteration: 8600\n",
            "Accuracy:0.9375\n",
            "Loss:0.2615261\n",
            "Iteration: 8700\n",
            "Accuracy:0.75\n",
            "Loss:0.787182\n",
            "Iteration: 8800\n",
            "Accuracy:0.75\n",
            "Loss:1.2773649\n",
            "Iteration: 8900\n",
            "Accuracy:0.8125\n",
            "Loss:1.2192794\n",
            "Iteration: 9000\n",
            "Accuracy:0.75\n",
            "Loss:0.42216453\n",
            "Independent Test set: 0.8974\n",
            "Iteration: 9100\n",
            "Accuracy:0.9375\n",
            "Loss:0.32657462\n",
            "Iteration: 9200\n",
            "Accuracy:0.75\n",
            "Loss:0.48033488\n",
            "Iteration: 9300\n",
            "Accuracy:0.9375\n",
            "Loss:0.1694371\n",
            "Iteration: 9400\n",
            "Accuracy:0.875\n",
            "Loss:0.30586115\n",
            "Iteration: 9500\n",
            "Accuracy:0.8125\n",
            "Loss:1.3862536\n",
            "Iteration: 9600\n",
            "Accuracy:0.8125\n",
            "Loss:1.0356262\n",
            "Iteration: 9700\n",
            "Accuracy:0.9375\n",
            "Loss:0.21681641\n",
            "Iteration: 9800\n",
            "Accuracy:0.8125\n",
            "Loss:0.56896096\n",
            "Iteration: 9900\n",
            "Accuracy:0.9375\n",
            "Loss:0.16736588\n",
            "Iteration: 10000\n",
            "Accuracy:0.875\n",
            "Loss:0.29700595\n",
            "Independent Test set: 0.8879\n",
            "Iteration: 10100\n",
            "Accuracy:0.875\n",
            "Loss:0.2726696\n",
            "Iteration: 10200\n",
            "Accuracy:0.6875\n",
            "Loss:0.8630082\n",
            "Iteration: 10300\n",
            "Accuracy:0.875\n",
            "Loss:0.23174495\n",
            "Iteration: 10400\n",
            "Accuracy:0.875\n",
            "Loss:0.24716465\n",
            "Iteration: 10500\n",
            "Accuracy:0.9375\n",
            "Loss:0.24795952\n",
            "Iteration: 10600\n",
            "Accuracy:0.8125\n",
            "Loss:0.70088917\n",
            "Iteration: 10700\n",
            "Accuracy:0.875\n",
            "Loss:0.42209303\n",
            "Iteration: 10800\n",
            "Accuracy:0.875\n",
            "Loss:0.38795865\n",
            "Iteration: 10900\n",
            "Accuracy:0.6875\n",
            "Loss:0.7169312\n",
            "Iteration: 11000\n",
            "Accuracy:0.8125\n",
            "Loss:0.35836744\n",
            "Independent Test set: 0.9061\n",
            "Iteration: 11100\n",
            "Accuracy:0.75\n",
            "Loss:1.0938452\n",
            "Iteration: 11200\n",
            "Accuracy:0.9375\n",
            "Loss:0.18393469\n",
            "Iteration: 11300\n",
            "Accuracy:0.75\n",
            "Loss:0.58590335\n",
            "Iteration: 11400\n",
            "Accuracy:0.8125\n",
            "Loss:0.69602454\n",
            "Iteration: 11500\n",
            "Accuracy:0.8125\n",
            "Loss:0.62379616\n",
            "Iteration: 11600\n",
            "Accuracy:0.9375\n",
            "Loss:0.22572592\n",
            "Iteration: 11700\n",
            "Accuracy:0.8125\n",
            "Loss:0.49048376\n",
            "Iteration: 11800\n",
            "Accuracy:0.9375\n",
            "Loss:0.49401847\n",
            "Iteration: 11900\n",
            "Accuracy:0.75\n",
            "Loss:0.6870218\n",
            "Iteration: 12000\n",
            "Accuracy:0.8125\n",
            "Loss:1.1838155\n",
            "Independent Test set: 0.9071\n",
            "Iteration: 12100\n",
            "Accuracy:0.8125\n",
            "Loss:0.50902367\n",
            "Iteration: 12200\n",
            "Accuracy:0.9375\n",
            "Loss:0.35592037\n",
            "Iteration: 12300\n",
            "Accuracy:0.625\n",
            "Loss:1.2618058\n",
            "Iteration: 12400\n",
            "Accuracy:0.9375\n",
            "Loss:0.4010989\n",
            "Iteration: 12500\n",
            "Accuracy:0.75\n",
            "Loss:0.33521017\n",
            "Iteration: 12600\n",
            "Accuracy:0.9375\n",
            "Loss:0.3702209\n",
            "Iteration: 12700\n",
            "Accuracy:0.9375\n",
            "Loss:0.11098638\n",
            "Iteration: 12800\n",
            "Accuracy:0.9375\n",
            "Loss:0.22040811\n",
            "Iteration: 12900\n",
            "Accuracy:0.625\n",
            "Loss:0.95081294\n",
            "Iteration: 13000\n",
            "Accuracy:0.8125\n",
            "Loss:0.52360183\n",
            "Independent Test set: 0.9045\n",
            "Iteration: 13100\n",
            "Accuracy:0.9375\n",
            "Loss:0.2227169\n",
            "Iteration: 13200\n",
            "Accuracy:0.8125\n",
            "Loss:0.56228244\n",
            "Iteration: 13300\n",
            "Accuracy:0.9375\n",
            "Loss:0.3087026\n",
            "Iteration: 13400\n",
            "Accuracy:0.75\n",
            "Loss:1.4835067\n",
            "Iteration: 13500\n",
            "Accuracy:0.875\n",
            "Loss:0.37177935\n",
            "Iteration: 13600\n",
            "Accuracy:1.0\n",
            "Loss:0.07547751\n",
            "Iteration: 13700\n",
            "Accuracy:0.8125\n",
            "Loss:0.43620643\n",
            "Iteration: 13800\n",
            "Accuracy:0.75\n",
            "Loss:0.39513385\n",
            "Iteration: 13900\n",
            "Accuracy:0.8125\n",
            "Loss:0.794362\n",
            "Iteration: 14000\n",
            "Accuracy:0.8125\n",
            "Loss:0.7262032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENFERMEDAD"
      ],
      "metadata": {
        "id": "hsbkNfo2Ybgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "CW3LZOnDWR9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow.compat.v1 as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "tf.compat.v1.disable_resource_variables()\n",
        "\n",
        "# Cargar el conjunto de datos de cáncer de mama\n",
        "data = load_breast_cancer()\n",
        "features = data.data\n",
        "labels = data.target\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalizar los datos\n",
        "scaler = StandardScaler()\n",
        "features_train = scaler.fit_transform(features_train)\n",
        "features_test = scaler.transform(features_test)\n",
        "\n",
        "# Convertir las etiquetas a one-hot encoding (en este caso, solo hay dos clases)\n",
        "labels_train_onehot = np.zeros((labels_train.shape[0], 2))\n",
        "labels_train_onehot[np.arange(labels_train.shape[0]), labels_train] = 1\n",
        "\n",
        "labels_test_onehot = np.zeros((labels_test.shape[0], 2))\n",
        "labels_test_onehot[np.arange(labels_test.shape[0]), labels_test] = 1\n",
        "\n",
        "# Set the parameters:\n",
        "NumClasses = 2  # Se ajusta al número de clases en el conjunto de datos de cáncer de mama\n",
        "BatchLength = 16\n",
        "Size = [features.shape[1], 1, 1]  # Ajustar el tamaño de entrada a la cantidad de características\n",
        "NumIteration = 40001\n",
        "LearningRate = 1e-4\n",
        "EvalFreq = 1000\n",
        "NumKernels = [16, 32, 64]\n",
        "\n",
        "# Spectral pooling size:\n",
        "#         1/2  - 0\n",
        "#         6/8 - 1\n",
        "specPoolSize = 0\n",
        "\n",
        "\n",
        "def fourier_complex_relu(x):\n",
        "    real = tf.real(x)\n",
        "    imag = tf.imag(x)\n",
        "    return tf.complex(tf.cast(real * real + imag * imag > 0.1, tf.float32) * real,\n",
        "                      tf.cast(real * real + imag * imag > 0.1, tf.float32) * imag)\n",
        "\n",
        "\n",
        "def convolution_in_freq_domain_without_ifft(f_input, out_channels):\n",
        "    in_shape = f_input.get_shape()\n",
        "    bias_r = tf.get_variable('BiasReal', [out_channels], dtype=tf.float32)\n",
        "    bias_c = tf.get_variable('BiasComp', [out_channels], dtype=tf.float32)\n",
        "    bias = tf.complex(bias_r, bias_c)\n",
        "    # Spectral pooling:\n",
        "    if specPoolSize == 0:\n",
        "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 4), int(in_shape[2] // 4), 0],\n",
        "                           [-1, int(in_shape[1] // 2), int(in_shape[2] // 2), in_shape[-1]])\n",
        "    elif specPoolSize == 1:\n",
        "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 8), int(in_shape[2] // 8), 0],\n",
        "                           [-1, int(in_shape[1]) - int(2 * in_shape[1] // 8), int(in_shape[2]) - int(2 * in_shape[2] // 8),\n",
        "                            in_shape[-1]])\n",
        "    in_shape = f_input.get_shape()\n",
        "    w_r = tf.get_variable('w_r', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
        "    w_i = tf.get_variable('w_i', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
        "    w = tf.complex(w_r, w_i)\n",
        "    fourier_kernel = w\n",
        "    fourier_kernel = tf.tile(tf.expand_dims(fourier_kernel, 0), [BatchLength, 1, 1, 1, 1])\n",
        "    out = []\n",
        "    for ind in range(out_channels):\n",
        "        res = tf.multiply(f_input[:, :, :, :], fourier_kernel[:, :, :, :, ind])\n",
        "        res = tf.add(res, bias[ind])\n",
        "        res = tf.expand_dims(tf.reduce_sum(res, 3), -1)\n",
        "        out.append(res)\n",
        "    out = tf.concat(out, 3)\n",
        "    norm_real = tf.keras.layers.BatchNormalization()(tf.real(out), training=True)\n",
        "    norm_comp = tf.keras.layers.BatchNormalization()(tf.imag(out), training=True)\n",
        "\n",
        "    out = tf.complex(norm_real, norm_comp)\n",
        "    out = fourier_complex_relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "InputData = tf.placeholder(tf.float32, [None] + Size)  # input images\n",
        "OneHotLabels = tf.placeholder(tf.int32, [None, NumClasses])  # the expected outputs, labels\n",
        "\n",
        "# Take the input to Fourier domain\n",
        "CurrentInput = tf.cast(InputData, tf.complex64)\n",
        "CurrentInput = tf.transpose(CurrentInput, [3, 0, 1, 2])\n",
        "fourierInput = tf.fft2d(CurrentInput, name=None)\n",
        "fourierInput = tf.transpose(fourierInput, [1, 2, 3, 0])\n",
        "fourierInput = tf.roll(fourierInput, shift=[int(Size[0] // 2), int(Size[1] // 2)], axis=[1, 2])\n",
        "CurrentFilters = Size[-1]\n",
        "\n",
        "# a loop which creates all layers\n",
        "for N in range(len(NumKernels)):\n",
        "    with tf.variable_scope('conv' + str(N)):\n",
        "        fourierInput = convolution_in_freq_domain_without_ifft(fourierInput, NumKernels[N])\n",
        "\n",
        "with tf.variable_scope('FC'):\n",
        "    fourierInput = tf.square(tf.real(fourierInput)) + tf.square(tf.imag(fourierInput))\n",
        "    CurrentShape = fourierInput.get_shape()\n",
        "    FeatureLength = int(CurrentShape[1] * CurrentShape[2] * CurrentShape[3])\n",
        "    FC = tf.reshape(fourierInput, [-1, FeatureLength])\n",
        "    W = tf.get_variable('W', [FeatureLength, NumClasses])\n",
        "    FC = tf.matmul(FC, W)\n",
        "    Bias = tf.get_variable('Bias', [NumClasses])\n",
        "    FC = tf.add(FC, Bias)\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    Loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=OneHotLabels, logits=FC))\n",
        "\n",
        "with tf.name_scope('optimizer'):\n",
        "    Optimizer = tf.train.AdamOptimizer(LearningRate).minimize(Loss)\n",
        "\n",
        "with tf.name_scope('accuracy'):\n",
        "    CorrectPredictions = tf.equal(tf.argmax(FC, 1), tf.argmax(OneHotLabels, 1))\n",
        "    Accuracy = tf.reduce_mean(tf.cast(CorrectPredictions, tf.float32))\n",
        "\n",
        "Init = tf.global_variables_initializer()\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.compat.v1.Session(config=config) as Sess:\n",
        "    Sess.run(Init)\n",
        "    Step = 1\n",
        "    while Step < NumIteration:\n",
        "        UsedInBatch = random.sample(range(features_train.shape[0]), BatchLength)\n",
        "        batch_xs = features_train[UsedInBatch, :]\n",
        "        batch_ys = labels_train_onehot[UsedInBatch, :]\n",
        "        batch_xs = np.reshape(batch_xs, [BatchLength] + Size)\n",
        "        _, Acc, L = Sess.run([Optimizer, Accuracy, Loss], feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "        if (Step % 100) == 0:\n",
        "            print(\"Iteration: \" + str(Step))\n",
        "            print(\"Accuracy:\" + str(Acc))\n",
        "            print(\"Loss:\" + str(L))\n",
        "        if (Step % EvalFreq) == 0:\n",
        "            SumAcc = 0.0\n",
        "            for i in range(0, features_test.shape[0]):\n",
        "                batch_xs = features_test[i, :]\n",
        "                batch_ys = labels_test_onehot[i, :]\n",
        "                batch_xs = np.reshape(batch_xs, [1] + Size)\n",
        "                batch_ys = np.reshape(batch_ys, [1, NumClasses])\n",
        "                a = Sess.run(Accuracy, feed_dict={InputData: batch_xs, OneHotLabels: batch_ys})\n",
        "                SumAcc += a\n",
        "            print(\"Independent Test set: \" + str(float(SumAcc) / features_test.shape[0]))\n",
        "        Step += 1\n",
        "\n",
        "    # Después de imprimir la forma de la salida\n",
        "    print(\"Forma de la salida:\", FC.shape)\n",
        "\n",
        "    # Visualizar algunas imágenes y sus predicciones\n",
        "    num_visualize = 5  # Puedes ajustar el número de imágenes a visualizar\n",
        "\n",
        "    # Seleccionar aleatoriamente algunas muestras del conjunto de prueba\n",
        "    visualize_indices = np.random.choice(features_test.shape[0], num_visualize, replace=False)\n",
        "\n",
        "    # Crear una sesión sin inicializar explícitamente las variables\n",
        "    for i in visualize_indices:\n",
        "        # Obtener la imagen y la etiqueta verdadera\n",
        "        input_image = features_test[i, :]\n",
        "        true_label = labels_test_onehot[i, :]\n",
        "\n",
        "        # Preprocesar la entrada para que sea compatible con la red neuronal\n",
        "        input_image = np.reshape(input_image, [1] + Size)\n",
        "\n",
        "        # Obtener la predicción del modelo\n",
        "        prediction = np.argmax(Sess.run(FC, feed_dict={InputData: input_image}), axis=1)\n",
        "\n",
        "        # Visualizar la imagen, la etiqueta verdadera y la predicción\n",
        "        plt.imshow(np.squeeze(input_image), cmap='gray')\n",
        "        plt.title(f'Etiqueta real: {np.argmax(true_label)}, Etiqueta predicha: {prediction[0]}')\n",
        "        plt.show()\n",
        "        plt.pause(2)  # Pausa de 2 segundos entre imágenes\n"
      ],
      "metadata": {
        "id": "XW76wfHaWJW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gbm8G-AfXXjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}