\chapter{Transformada Rápida de Fourier}






\section{Motivación}
La Transformada Rápida de Fourier (FFT) es un algoritmo eficiente para calcular la Transformada de Fourier Discreta  y su inversa.

\noindent Su impacto en la era moderna es incalculable, prueba de ello es su inclusión por la revista IEEE de Computación en Ciencia e Ingeniería como uno de  los 10 algoritmos más influyentes en el desarrollo y la práctica de la ciencia y la ingeniería en el siglo XX [ref]


\noindent El capítulo comienza  contextualizando al lector con algunos referencias históricas del algoritmo.  Posteriormente avanzaremos con el desarrollo teórico que sustenta la FFT donde usaremos fundamentalmente la teoría desarrollada previamente. Este análisis  culminará con el estudio de la mejora en eficiencia en  comparación con el método directo y una implementación recursiva para un caso particular.


\noindent Para finalizar el capítulo se abordarán algunas de las aplicaciones en diversos campos, particularmente en el ámbito de visión por computador. Con esto se pretende convencer al lector de que la FFT se encuentra prácticamente en cualquier aplicación que involucre el análisis y procesamiento de señales.




\section{Historia}












Nos remontamos a 1945, año en el que finaliza la la Segunda Guerra Mundial tras el lanzamiento de las primeras bombas atómicas usadas directamente sobre una población civil en Japón por parte de Estados Unidos. Este acontecimiento desencadenó en  una imperiosa necesidad por parte de las naciones de controlar la proliferación nuclear al comprobar el grado de destrucción que podían provocar.

\noindent Como resultado, Estados Unidos celebró conversaciones con los soviéticos y otras naciones con capacidad nuclear con el objetivo final de detener la carrera de armamento nuclear.

\noindent Para hacerlo se trató de llegar a determinados acuerdos que prohibían la experimentación con energía nuclear. Sin embargo debido a la esperable desconfianza entre países, era necesario que cada nación tuviera la tecnología para identificar las pruebas nucleares realizadas por otros. 

\noindent Los hidrófonos podían detectarlas bajo el mar y los átomos residuales podían identificarse en el cielo desde pruebas en tierra. Pero detectar las pruebas subterraneas era todo un desafío.


\noindent Una idea era analizar series temporales
sismológicas obtenidas de sismómetros situados en distintos lugares estratégicos para estudiar estas señales y deducir si se trataba de un exprimento nuclear.
Dentro de una señal compleja, hay muchas ondas sinusoidales de diferentes frecuencias, todas contribuyendo a formar el resultado final, y esto puede descifrarse si podemos aislar cada frecuencia. Para ello  recurrieron a la DFT que permitía descomponer la señal en distintas frecuencias, sin embargo  debido a la gran complejidad computacional que se necesitaba este método era imposible de poner en práctica incluso con los ordenadores actuales.

\noindent No fue hasta 1960,cuando James Cooley y John Tukey  publicaron el algoritmo de FFT que reducía considerablemente el orden de complejidad de la DFT, pudiendo reducir el tiempo de cálculo de más de tres años a 35 minutos.

\noindent Trágicamente, era demasiado tarde para firmar una prohibición de pruebas completa, y las pruebas nucleares fueron forzadas bajo tierra, donde aumentaron a una notable tasa de alrededor de una vez por semana.

\noindent Desde entonces, la FFT ha encontrado nuevos usos en casi todas las aplicaciones de comunicaciones y señalización de datos. Sin embargo, tenía el potencial de ser mucho mayor: casi fue el algoritmo que detuvo la carrera armamentista nuclear, si hubiera llegado solo unos años antes.


\noindent Lo más fascinante es que la primera aparición de la Transformada Rápida de Fourier (FFT) data de 1807 del matemático Gauss.
Sus intereses estaban en ciertos cálculos astronómicos (un área recurrente de aplicación de la FFT) relacionados con la interpolación de órbitas asteroidales a partir de un conjunto finito de observaciones equidistantes. Seguramente, la perspectiva de un cálculo manual laborioso y extenso era una buena motivación para el desarrollo de un algoritmo rápido. Sin embargo su trabajo no fue publicado y apareció únicamente en sus obras recopiladas como un manuscrito inédito  [ref].

\noindent Algunos trabajos previos en los que Cooley y Tukey se basaron se mencionan a continuación.

\noindent Un método eficiente para el cálculo de las interacciones de un experimento factorial $2^m$ fue introducido por Yates[1]. La generalización a $3^m$ fue proporcionada por Box et al. [1]. Good [2] generalizó estos métodos y proporcionó algoritmos elegantes, para los cuales una clase de aplicaciones es el cálculo de series de Fourier.

\noindent Otro precursor importante es el trabajo de Danielson y Lanczos, realizado en el servicio de la cristalografía de rayos X, otro usuario frecuente de la tecnología FFT. [ref]

\noindent A lo largo de la historia, estos y numerosos otros nombres han estado vinculados al algoritmo FFT culminado con Cooley y Tukey.
"Esto puede servir como motivación para explorar no solo enfoques novedosos, sino también para revisitar de vez en cuando viejos documentos y descubrir la diversidad de trucos e ideas ingeniosas que se empleaban en una época en la que el cálculo era una tarea laboriosa. Quizás entre las ideas descartadas antes de la era de las computadoras electrónicas, podamos encontrar valiosas semillas para nuevos algoritmos." [ref]

\begin{definicion}
    Orden de Complejidad, definir y decir clases de complejodad y llamarle T y presentar los ordenes de complejidad que vienen a continaución importante.
    Y difernecia entre complejidad del problema y del algoritmo y tal
\end{definicion}


\section{Método Directo}
Si atendemos a la expresión de la DFT.El enfoque directo implica utilizar el método de fuerza bruta, mediante el cual debemos realizar cada sumatoria para cada elemento de la N-tupla cuya transformada deseamos calcular.

\noindent De este modo, dada una N-tupla $x = [x_0,..,x_{N-1}]$ calcular la DFT  de $x$ implica para cada  $j \in \{0,...,N-1\}$ realizar $N$ operaciones.
Por tanto para calcular la salida completa se necesitarían $N$ operaciones por cada índice $j \in \{0,...,N-1\}$ lo que nos lleva a un total de $N^2$ operaciones.
Y por tanto tiene un orden de complejidad cuadrático $T = O(N^2)$
\begin{ejemplo}
\noindent Si disponemos de una imagen de $2048 \times 2048$ (tamaño habitual), esto significaría realizar del orden de 17 mil millones de operaciones para calcular una única 2DFT excluyendo las exponenciales que podrían calcularse una única vez y almacenarse.

\noindent  Mientras que calcular la FFT 2-D de una imagen de $2048 \times 2048$ requeriría del orden de 92 millones de operaciones, lo cual representa una reducción significativa respecto a los mil millones de cálculos mencionados anteriormente. 
\begin{observacion}
  \noindent En ambos casos se ha tenido en cuenta la factorización de una 2DFT en 1DFT para realizar una comparación justa.[insertar imagen grande ¿?]
\end{observacion}
\end{ejemplo}

\begin{observacion}
    Una operación consiste en una multiplicación y una suma de dos números complejos.
\end{observacion}

\section{FFT}
Sea $W_N = e^{\frac{-2\pi i}{N}}$ la $N$-ésima raíz de la unidad. 
La 1-DFT de $f = (f[0],f[1],\ldots,f[N-1])$ puede reescribirse como $F = (F[0],F[1],\ldots,F[N-1])$ donde:
\begin{equation}\label{}
    F[j] = \sum_{k=0}^{N-1} f[k] W_{N}^{jk}, \quad j \in \{0,1,\ldots,N-1\}
\end{equation}


\begin{teorema}
Sea  $N$  compuesto con factorización $N = r_1 \cdot r_2$ con $r_1,r_2$ divisores naturales no triviales de $N$.
La DFT de una $N$-tupla $f$  puede ser calculada en $T=O(N(r_1+r_2))$ 
\end{teorema}


\vspace{0.2cm}


\begin{proof}
    \noindent Reescribimos los índices $j,k$ como sigue:
\begin{equation*}
    j = j_1r_1+j_0  \quad  j_0 \in \{0,1,\ldots r_1-1\}, j_1 \in \{0,1,\ldots r_2-1\}
\end{equation*}
\begin{equation*}
     k = k_1r_1+k_0   \quad  k_0 \in \{0,1,\ldots r_2-1\}, k_1 \in \{0,1,\ldots r_1-1\}
\end{equation*}

\noindent Esto nos permite escribir la DFT en función de $j_0,j_1,k_0,k_1$.

\begin{align}
    F[(j_1,j_0)] &= \sum_{k_0=0}^{r_2-1}  \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{(j_1r_1+j_0)(k_1r_2+k_0)} \nonumber \\
    &= \sum_{k_0=0}^{r_2-1}  \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{(j_1r_1+j_0)k_1r_2}W_N^{(j_1r_1+j_0)k_0}  \nonumber \\
    &= \sum_{k_0=0}^{r_2-1}  \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{j_0k_1r_2}W_N^{(j_1r_1+j_0)(k_0)}  \label{eq:fft3}
\end{align}

\noindent La última igualdad se justifica con:

\begin{equation}
    W_N^{(j_1r_1+j_0)k_1r_2} =  W_N^{j_1k_1r_1r_2}W_N^{j_0k_1r_2}=
    W_N^{j_1k_1N}W_N^{j_0k_1r_2}=W_N^{j_0k_1r_2}
\end{equation}
\noindent donde se ha usado que $W_N$ es la raíz enésima de la unidad.
Notamos que $f(k_1,k_0) W_N^{j_0k_1r_2}$ depende únicamente de $j_0$ y no de $k_0$. Esto nos permite definir la N-tupla $f_1$ como 
\begin{equation}\label{eq:fft1}
    f_1(j_0,k_0) = \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{j_0k_1r_2}
\end{equation}
y podemos escribir ~\eqref{eq:fft3} en función de $f_1$

\begin{equation}\label{eq:fft2}
    F[(j_1,j_0)] = \sum_{k_0=0}^{r_2-1}  f_1(j_0,k_0)W_N^{(j_1r_1+j_0)(k_0)} 
\end{equation}

\noindent Observamos que reescribiendo los índices hemos podido desacoplar las dos sumatorias. Esta es la clave del cálculo de la FFT.


\indent Como $f_1$ es una $N$-tupla y cada elemento se calcula usando $r_1$ operaciones,necesitamos por un lado $Nr_1$ operaciones para el cáculo de $f_1$. Una vez obtenido $f_1$, $F$ es calculado en $r_2$ operaciones por cada elemento lo que nos deja un total de $Nr_2$ operaciones.
En total el algoritmo regido por las ecuaciones  ~\eqref{eq:fft1}, ~\eqref{eq:fft2} es del orden de $O(N(r_1+r_2))$
\end{proof}


\begin{teorema}
Sea $N$ compuesto con factorización $N = \gamma_1 \cdot \gamma_2 \cdot \ldots \cdot r_m$ con $\gamma_1, \gamma_2, \ldots, \gamma_m$ divisores naturales no triviales de $N$.
La DFT de una $N$-tupla $f$ puede ser calculada en $T = O(N(\gamma_1 + \gamma_2 + \ldots + \gamma_m))$.
\end{teorema}

\begin{proof}

La demostración consiste en un razonamiento recursivo. Se tiene que si $N = \gamma_1 \cdot \gamma_2 \cdot \ldots \cdot \gamma_m$ con $\gamma_1, \gamma_2, \ldots, \gamma_m$ dando $m$ pasos en el algoritmo anteriormente descrito se deduce que  $T=O(N(\gamma_1 + \gamma_2 + \ldots + \gamma_m))$.

\textbf{NO ESTÁ BIEN pero ns como hacerlo :}.
Aplicaremos por tanto m veces el algoritmo descrito en [ref teorema anterior].Consideraremos en cada paso las variables $r_1$ y $r_2$ para una mayor claridad estas se irán renombrando en cada paso del algoritmo.Los índices $j_O,j_1,k_0,k_1$ serán los relativos al cálculo seguido en el caso anterior para la  factorización $N= r_1r_2$.

\vspace{0.1cm}
\boxed{Paso 1}

Sea  $ N_1 =  \underbrace{\gamma_1}_{r_1} \cdot \underbrace{\gamma_2 \cdot \ldots \cdot \gamma_m}_{r_2}$.

\begin{equation}
    F[(j_1,j_0)] = \sum_{k_0=0}^{r_2-1}  f_1(j_0,k_0)W_N^{(j_1r_1+j_0)(k_0)} = \sum_{k=0}^{r_2-1}  f_1(k)W_N^{jk} 
\end{equation}

donde $f_2$ es calculado usando $\gamma_1N$ operaciones mediante la siguiente expresión:
\begin{equation}
    f_1(j_0,k_0) = \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{j_0k_1r_2}
\end{equation}
\vspace{0.1cm}
 
\boxed{Paso 2}
\vspace{0.1cm}

Sea $N_2 = \underbrace{\gamma_2}_{r_1} \cdot \underbrace{ \gamma_3 \cdot \ldots \cdot \gamma_m}_{r_2}$.
Aplicamos el proceso de nuevo ahora para la ecuación 
\begin{equation}\label{eq:fft2}
    F[j] = \sum_{k=0}^{N_2-1}  f_1(k)W_N^{jk}  
\end{equation}
Lo que nos deja con 
\begin{equation}\label{eq:fft2}
      F[j_s0,j_1]  = \sum_{k_0=0}^{r_2-1}  f_2(j_0,k_0)W_N^{(j_1r_1+j_0)(k_0)} = \sum_{k=0}^{r_2-1}  f_2(k)W_N^{jk} 
\end{equation}
donde $f_2$ es calculado usando $\gamma_2N$ operaciones mediante la siguiente expresión:
\begin{equation}\label{eq:fft1}
    f_2(j_0,k_0) = \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{j_0k_1r_2}
\end{equation}


\boxed{Paso m}
\vspace{0.1cm}

Sea $N_m$ = $\underbrace{\gamma_{m-1}}_{r_1} \cdot \underbrace{\gamma_m}_{r_2}$.
Aplicamos el proceso de nuevo ahora para la ecuación 
\begin{equation}\label{eq:fft2}
   F[j] = \sum_{k=0}^{r_2-1}  f_m(k)W_N^{jk}  
\end{equation}
Lo que nos deja con 
\begin{equation}\label{eq:fft2}
    F[(j_1,j_0)] = \sum_{k_0=0}^{r_2-1}  f_2(j_0,k_0)W_N^{(j_1r_1+j_0)(k_0)} = \sum_{k=0}^{r_2-1}  f_1(k)W_N^{jk} 
\end{equation}

donde $f_m$ es calculado usando $\gamma_{m-1}N$ operaciones mediante la siguiente expresión: 
\begin{equation}\label{eq:fft1}
    f_m(j_0,k_0) = \sum_{k_1=0}^{r_1-1} f(k_1,k_0) W_N^{j_0k_1r_2}
\end{equation}
Finalmente concluimos con $r_mN$ operaciones el cálculo de $F$.

Lo que nos deja un total de $O(N(r_1+ \ldots r_m))$

Lo dejo apartado y ya está.





\end{proof}


\begin{observacion}
    Si queremos minimizar el orden de complejidad $T$, debemos usar tantos factores de $N$ como sea posible. Es decir si $N = r_1 \cdot r_2 \cdot \ldots \cdot r_m$ y dado $j \in \{1, \ldots m\}$ se tiene que $r_j = p_1p_2$ con $p_1,p_2>1$   entonces $p_1+p_2 < r_j$ salvo que  $p_1=p_2=2$.
    Y por consiguiente $O(N(r_1 + r_2 + \ldots + r_j + \ldots + r_m))$ tiene mayor orden de complejidad que $T=O(N(r_1 + r_2 + \ldots + p_1+p_2+ \ldots r_m))$.
    La igualdad se da  para $p_1=p_2=2$, de donde deducimos que el factor $2$ puede combinarse de manera indistinta sin pérdida alguna.
\end{observacion}


\textbf{hablar sobre la memoria tb}


\noindent Luego, al descomponer un número en factores, observamos una disminución del orden de complejidad. Por lo tanto, podemos inferir que los números con un mayor número de divisores proporcionarán una ganancia en eficiencia mayor.Esto motiva la siguiente definición:

\begin{definicion}
    Un número antiprimo o altamente compuesto es un entero positivo con más divisores que cualquier entero positivo más pequeño
\end{definicion}


\noindent Ramanujan (1915) enumeró 102 números altamente compuestos hasta 6746328388800, pero omitió algunos de ellos. Robin (1983) proporciona los primeros 5000 números altamente compuestos, y una encuesta exhaustiva se da por Nicholas (1988). Flammenkamp da una lista de los primeros 779674 números altamente compuestos.

\begin{ejemplo}
Son números antiprimos el 1, 2, 4, 6, 12, 24, 36, 48, 60.
\end{ejemplo}


\begin{proposicion}
  \noindent Si $N = 2^{a_2}3^{a_3} \cdots p^{a_p}$ es la factorización prima de un número altamente compuesto, \textbf{entonces}:
\end{proposicion}

\begin{itemize}
\item Los primos 2, 3, ..., p forman una secuencia de primos consecutivos,

\item Los exponentes son no decrecientes, por lo que \( a_2 \geq a_3 \geq \ldots \geq a_p \), y

\end{itemize}

\textbf{No lo se bien falta buscar mas datos sobre estos numeros}

\begin{proposicion}
    El algoritmo FFT proporciona ganancias significativas cuando el tamaño de entrada $N$ es un número altamente compuesto. 
\end{proposicion}

\begin{proof}
   El orden de complejidad de la FFT con una entrada de tamaño $N$ con  $N = p_1^{a_1}p_2^{a_2} \ldots p_m^{a_m}$ es $T= O(N(a_1\cdot p_1+a_2\cdot p_2+ \ldots a_m\cdot p_m$))

   \noindent Luego, 
    \begin{equation}
        \frac{T}{N} = a_1\cdot p_1+a_2\cdot p_2+ \cdots + a_m\cdot p_m
    \end{equation}
\end{proof}

Aplicando log en base 2 \textbf{(por qué)}

\begin{equation}
    log_2N = log_2(a_1)\cdot p_1+log_2(a_2)\cdot p_2+ \ldots log_2(a_m)\cdot p_m
\end{equation}

De donde obtenemos
\begin{equation}
    \frac{T}{Nlog(N)} =  \frac{a_1\cdot p_1+a_2\cdot p_2+ \ldots a_m\cdot p_m}{log_2(a_1)\cdot p_1+log_2(a_2)\cdot p_2+ \ldots log_2(a_m)\cdot p_m}
\end{equation}

\noindent Cuando el número $N$ es altamente compositivo el término de la derecha se acota por una constante  $C$, y por tanto $\frac{T}{Nlog(N)} = C $, lo que implica que el orden de complejidad es de $T= O(Nlog(N)$. \textbf{esto deberíamos comprobarlo} \textbf{y quizás hablar sobre el tema de las ganancias}








\textbf{distinguie para los numeros para los que hay mas ganancia y hacer alguna grafica} comprobar porque no tengo claro lo de los números \textbf{}
Y grafica


\begin{proposicion}
 Si tomamos $r_1 = r_2 = \ldots = r_m = r$ entonces  $m = log_rN$ y  el número total de operaciones para el cálculo de la FFT con tamaño de entrada $N =r^m$  es $T(r) = rNlog_rN $
\end{proposicion}
\begin{proof}
Se deduce del teorema 5.2 [ref]

\end{proof}

\noindent El caso $r=2$ y $r=4$ es de especial interés a nivel computacional, ya que el algoritmo ofrece ciertas ventajas añadidas tanto en el direccionamiento como en las operaciones realizadas como consecuencia de la naturaleza binaria inherente a los ordenadores.

Detallaremos el caso $r = 2$. La lógica seguida durante el proceso es similar a la ya aplicada anteriormente.

Sea $N = 2^m$, expresamos los índices $j,k$ en [ref] como 
\begin{equation}
    j = j_{m-1}\cdot 2^{m-1}+ \ldots j_{1}\cdot 2 + j_0, \quad j_i \in \{0,1\} \quad \forall i \in \{0, \ldots m-1\}
\end{equation}
\begin{equation}
    k = k_{m-1}\cdot 2^{m-1}+ \ldots k_{1}\cdot 2 + k_0, \quad k_i \in \{0,1\} \quad \forall i \in \{0, \ldots m-1\}
\end{equation}
La clave está en que esta expresión de $j,k$ coincide con  la descomposición binaria de cada índice. De tal modo que $j_i, k_i$ refieren al bit que ocupa la posición $i$ de la representación binaria de $j$ y $k$ respectivamente, y por tanto solo pueden tomar el valor $0,1$.
Escribiremos entonces [ref def] en función de sus índices.Luego, \textbf{no lo tengo claro}

\begin{align}
    F[(j_1,j_0)] &= \sum_{k_0=0}^{1}  \sum_{k_1=0}^{1} \ldots \sum_{k_{m-1}=0}^{1} f(k_{m-1}, \ldots, k_0) W_N^{jk_{m-1}{2^{m-1}+ \ldots + jk_0}}
\end{align}

\noindent Siguiendo un razonamiento similar a [ref]. Como consecuencia de $W_N^N =1$.

\begin{equation}
    W_N^{jk_{m-1}{2^{m-1}}} =  W_N^{(j_{m-1}\cdot 2^{m-1}+ \ldots j_{1}\cdot 2 + j_0)k_{m-1}{2^{m-1}}}=W_N^{j_0k_{m-1}{2^{m-1}}}
\end{equation}

\noindent Esto nos permite  desacoplar la suma interior $f_1$ y calcularla directamtente  como 
\begin{equation}
    f_1 (j_0, k_{m-2}, \ldots k_0) = \sum_{k_{m-1}=0}^{1} f(k_{m-1}, \ldots, k_0) W_N^{j_0k_{m-1}{2^{m-1}}}
\end{equation}
ya que sólo depende de $j_0$.

\noindent Se procede de igual forma con el resto de índices desacoplando las distintas sumatorias.

\noindent De manera que en general para $l \in \{1, \ldots m\}$ tendríamos

\begin{equation}
    f_l (j_0, \ldots, j_{l-1},k_{m-l-1}, \ldots k_0) = \sum_{k_{m-l}=0}^{1} f_{l-1}(j_0, \ldots, j_{l-2},k_{m-l}, \ldots k_0)W_N^{(j_{l-1}2^{l-1}+\ldots+j_0)k_{m-l}2^{m-l}}
\end{equation}

\noindent donde hemos usado

\begin{equation}
    W_N^{jk_{m-l}{2^{m-l}}} =  W_N^{(j_{m-1}\cdot 2^{m-1}+ \ldots j_{1}\cdot 2 + j_0)k_{m-l}{2^{m-l}}}=W_N^{j_0k_{m-l}{2^{m-l}}}
\end{equation}
Podemos desarrollar la sumatoria y usar que $e^{i\pi}=-1$ $e^{i\frac{\pi}{2}=i}$
\begin{align*}
&f_l(j_0, \ldots, j_{l-1},k_{m-l-1}, \ldots, k_0) \\
&\quad = f_{l-1}(j_0, \ldots, j_{l-2},0,k_{m-l-1}, \ldots, k_0) \\
&\quad\quad + (-1)^{j_{l-1}}i^{j_{l-2}}f_{l-1}(j_0, \ldots, j_{l-2},1,k_{m-l-1}, \ldots, k_0)W_N^{(j_{l-3}2^{l-3}+\ldots+j_0)2^{m-l}} \quad j_{l-1} \in \{0,1\}  
\end{align*}

\noindent De acuerdo con la convención de indexación, esto se almacena en una ubicación cuyo índice es
\[ j_02^{m-1} + \cdot \cdot \cdot + j_{l-1}2^{m-l} + k_{m-l-1}2^{m-l-1} + \cdot \cdot \cdot + k_0 \]
Se puede observar en [ref] que solo están involucradas en el cálculo las dos ubicaciones de almacenamiento con índices que tienen $0$ y $1$ en la posición del bit \(2^{m-1}\). 

\noindent Además la computación paralela está permitida, ya que la operación descrita por [ref] se puede llevar a cabo con todos los valores de \(j_0, \cdot \cdot \cdot, j_{i-2}\) y \(k_0, \cdot \cdot \cdot, k_{m-i-1}\) simultáneamente. En algunas aplicaciones, es conveniente usar (20) para expresar \(A_i\) en términos de \(A_{i-2}\), lo que equivale a un  con \(r = 4\).

\noindent El último array $f_m$ calculado proporciona el resultado deseado de la siguiente manera.
\[ F(j_{m-i}, \ldots, j_0) = f_{m} (j_{0}, \ldots, j_{m-1}) \]




\section{Algoritmos} 
\textbf{(no se cuantos poner ni como de profundos explicarlos)}
Presentamos ahora algunos de los algoritmo más usados para la implementación de la transformada rápida de Fourier.

\textbf{RADIX-2:}

Implementación recursiva del  algoritmo FFT para el caso $N=2^m$.

\begin{algorithm}
\caption{FFT (Radix-2)}
\label{alg:fft}
\begin{algorithmic}[1]
\Procedure{FFT}{$A$}
    \State \textbf{Entrada:} Un array de valores complejos con tamaño $2^m$ para $m \geq 0$.
    \State \textbf{Salida:} Un array de valores complejos que es la DFT de la entrada.
    \State $N := \text{longitud}(A)$
    \If{$N = 1$}
        \State \textbf{devolver} $A$
    \Else
        \State $W_N := e^{\frac{2\pi i}{N}}$
        \State $W := 1$
        \State $A_{\text{par}} := (A_0, A_2, \ldots, A_{N-2})$
        \State $A_{\text{impar}} := (A_1, A_3, \ldots, A_{N-1})$
        \State $Y_{\text{par}} := \text{FFT}(A_{\text{par}})$
        \State $Y_{\text{impar}} := \text{FFT}(A_{\text{impar}})$
        \For{$j := 0$ \textbf{hasta} $\frac{N}{2} - 1$}
            \State $Y[j] = Y_{\text{par}}[j] + W \cdot Y_{\text{impar}}[j]$
            \State $Y[j + \frac{N}{2}] = Y_{\text{par}}[j] - W \cdot Y_{\text{impar}}[j]$
            \State $W := W \cdot W_N$
        \EndFor
        \State \textbf{devolver} $Y$
    \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}



\textbf{RADIX-4:}

Implementación recursiva del  algoritmo FFT para el caso $N=4^m$.









\section{Rader}
El algoritmo de Cooley-Tukey de la FFT no contempla para $N$ primo ninguna mejora.
La mayoría de algoritmos de la FFT aplican en este caso un zero-padding  a la potencia de 2 más cercana para aproximar la transformada de fourier continua.
Sin embargo si lo que se quiere es calcular la DFT de una secuencia de elementos podemos recurrir al algoritmo de Rader que utiliza la teoría de números  para proporcionar una alternativa en este caso.


Recordamos que  $\mathbb{Z}_p = \mathbb{Z}/p$, esto es, el anillo cociente $\mathbb{Z}$ módulo el ideal  ${p\mathbb{Z}}$, que es un cuerpo gracias a que $p\mathbb{Z}$ es un ideal maximal.
Denotamos por $\mathbb{Z}_p^\times$ las unidades de 
$\mathbb{Z}_p.$

\begin{teorema}
        $\mathbb{Z}_p^\times$ es un grupo cíclico.
\end{teorema}

\begin{teorema}
    (Teorema de Fermat)
\end{teorema}

El algoritmo de Rader consiste por tanto en :
 



bla bla


primos de sophie germain y cadena ytal.
----------------------------------



 








